---
layout: post
title: "claude "
date: 2025-08-05 14:42:00 +0800
categories: gather
---
### ç”¨æˆ·:
# é¡¹ç›®ç»“æ„
```
src/
â”œâ”€â”€ main.rs
â”œâ”€â”€ config.rs
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ models.rs
â”‚   â””â”€â”€ init.rs
â”œâ”€â”€ handlers/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ auth.rs
â”‚   â”œâ”€â”€ comments.rs
â”‚   â””â”€â”€ health.rs
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ mod.rs
â”‚   â”œâ”€â”€ auth_service.rs
â”‚   â”œâ”€â”€ comment_service.rs
â”‚   â””â”€â”€ vote_service.rs
â””â”€â”€ utils/
    â”œâ”€â”€ mod.rs
    â””â”€â”€ cors.rs
```,å¸®æˆ‘åŠ å…¥æ–‡ç« ç®¡ç†ï¼ˆåŸºæœ¬çš„get, post)å’Œå…¶å®ƒå®ç”¨çš„åŠŸèƒ½ï¼Œä¸€ç¯‡æ–‡ç« åŒ…å«ç±»åˆ«ï¼Œæ ‡ç­¾æ ‡é¢˜ï¼Œæ ‡é¢˜å›¾ç‰‡url,å†…å®¹ï¼ˆmdæ ¼å¼ï¼‰ï¼Œåˆ›å»ºæ—¥æœŸï¼Œå†åŠ å…¥**GraphQLçš„ç‰¹æ€§è¿›å»**
main.rs->->// ## src/main.rs
mod config;
mod database;
mod handlers;
mod services;
mod utils;

use axum::{
    routing::{get, post},
    Router,
};
use std::net::SocketAddr;
use tokio::net::TcpListener;

use config::AppConfig;
use database::init::init_database;
use handlers::{auth, comments, health};
use utils::cors::create_cors_layer;

#[tokio::main]
async fn main() {
    println!("ğŸš€ å¯åŠ¨åº”ç”¨ç¨‹åº...");

    // åˆå§‹åŒ–é…ç½®
    let config = AppConfig::from_env();

    // åˆ›å»ºæ•°æ®åº“è¿æ¥æ± 
    let pool = config.create_db_pool().expect("æ— æ³•åˆ›å»ºæ•°æ®åº“è¿æ¥æ± ");

    // åˆå§‹åŒ–æ•°æ®åº“
    if let Err(e) = init_database(&pool).await {
        eprintln!("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {:?}", e);
        std::process::exit(1);
    }
    println!("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ");

    // åˆ›å»ºè·¯ç”±
    let app = Router::new()
        .route("/", get(health::health_check))
        .route("/api/health", get(health::health_check))
        .route("/api/google-login", post(auth::handle_google_login))
        .route("/api/google-logout", post(auth::handle_google_logout))
        .route("/api/comments", get(comments::get_comments))
        .route("/api/comments", post(comments::create_comment))
        .route("/api/comments/vote", post(comments::handle_vote))
        .with_state(pool)
        .layer(create_cors_layer());

    let addr = SocketAddr::from(([0, 0, 0, 0], config.port));

    println!("ğŸš€ æœåŠ¡è¿è¡Œåœ¨ http://0.0.0.0:{}", config.port);
    println!("ğŸ”— æœ¬åœ°è®¿é—®: http://localhost:{}", config.port);
    println!("ğŸ’¬ è®¨è®ºåŒºåŠŸèƒ½å·²å¯ç”¨");
    println!("ğŸ—³ï¸ æŠ•ç¥¨åŠŸèƒ½å·²å¯ç”¨");
    println!("ğŸ’­ å›å¤åŠŸèƒ½å·²å¯ç”¨");
    println!("ğŸ—„ï¸ ä½¿ç”¨ PostgreSQL æ•°æ®åº“: {}", config.db_name);

    let listener = TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}
 config.rs->->// ## src/config.rs
use deadpool_postgres::{Config, Pool, Runtime};
use tokio_postgres::NoTls;

pub struct AppConfig {
    pub port: u16,
    pub db_host: String,
    pub db_port: u16,
    pub db_user: String,
    pub db_password: String,
    pub db_name: String,
}

impl AppConfig {
    pub fn from_env() -> Self {
        Self {
            port: std::env::var("PORT")
                .unwrap_or_else(|_| "3001".to_string())
                .parse()
                .expect("PORT must be a valid number"),
            db_host: std::env::var("DB_HOST").unwrap_or_else(|_| "localhost".to_string()),
            db_port: std::env::var("DB_PORT")
                .unwrap_or_else(|_| "5432".to_string())
                .parse()
                .expect("DB_PORT must be a valid number"),
            db_user: std::env::var("DB_USER").unwrap_or_else(|_| "postgres".to_string()),
            db_password: std::env::var("DB_PASSWORD").unwrap_or_else(|_| "zz123123".to_string()),
            db_name: std::env::var("DB_NAME").unwrap_or_else(|_| "user_comments".to_string()),
        }
    }

    pub fn create_db_pool(&self) -> Result<Pool, Box<dyn std::error::Error>> {
        let mut cfg = Config::new();
        cfg.host = Some(self.db_host.clone());
        cfg.port = Some(self.db_port);
        cfg.user = Some(self.db_user.clone());
        cfg.password = Some(self.db_password.clone());
        cfg.dbname = Some(self.db_name.clone());

        Ok(cfg.create_pool(Some(Runtime::Tokio1), NoTls)?)
    }
}
 init.rs->->// ## src/database/init.rs
use deadpool_postgres::Pool;

pub async fn init_database(pool: &Pool) -> Result<(), Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // åˆ›å»ºç”¨æˆ·è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS users (
            id BIGSERIAL PRIMARY KEY,
            google_id TEXT UNIQUE NOT NULL,
            email TEXT NOT NULL,
            name TEXT NOT NULL,
            picture TEXT,
            created_at TIMESTAMPTZ NOT NULL,
            last_login TIMESTAMPTZ NOT NULL
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºè¯„è®ºè¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS comments (
            id TEXT PRIMARY KEY,
            content TEXT NOT NULL,
            author_name TEXT NOT NULL,
            author_email TEXT NOT NULL,
            author_picture TEXT NOT NULL,
            parent_id TEXT NULL,
            created_at TIMESTAMPTZ NOT NULL,
            FOREIGN KEY (parent_id) REFERENCES comments (id) ON DELETE CASCADE
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºæŠ•ç¥¨è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS comment_votes (
            id BIGSERIAL PRIMARY KEY,
            comment_id TEXT NOT NULL,
            user_email TEXT NOT NULL,
            vote_type TEXT NOT NULL CHECK (vote_type IN ('up', 'down')),
            created_at TIMESTAMPTZ NOT NULL,
            UNIQUE(comment_id, user_email),
            FOREIGN KEY (comment_id) REFERENCES comments (id) ON DELETE CASCADE
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºç´¢å¼•
    create_indexes(&client).await?;

    Ok(())
}

async fn create_indexes(client: &tokio_postgres::Client) -> Result<(), tokio_postgres::Error> {
    let indexes = [
        "CREATE INDEX IF NOT EXISTS idx_comments_created_at ON comments (created_at DESC)",
        "CREATE INDEX IF NOT EXISTS idx_comments_parent_id ON comments (parent_id)",
        "CREATE INDEX IF NOT EXISTS idx_users_google_id ON users (google_id)",
        "CREATE INDEX IF NOT EXISTS idx_users_email ON users (email)",
        "CREATE INDEX IF NOT EXISTS idx_votes_comment_user ON comment_votes (comment_id, user_email)",
    ];

    for &index_sql in &indexes {
        client.execute(index_sql, &[]).await?;
    }

    Ok(())
}
 models.rs->->// ## src/database/models.rs
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};

// å‰ç«¯å‘é€çš„æ•°æ®æ ¼å¼
#[derive(Deserialize)]
pub struct GoogleLoginPayload {
    pub credential: String, // ID token
}

// è§£æ Google è¿”å›çš„ token ä¿¡æ¯
#[derive(Debug, Deserialize)]
pub struct GoogleUserInfo {
    pub email: String,
    pub name: String,
    #[allow(dead_code)]
    pub picture: Option<String>,
    pub sub: String, // ç”¨æˆ·å”¯ä¸€æ ‡è¯†
}

// ç”¨æˆ·æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct User {
    pub id: i64,
    pub google_id: String,
    pub email: String,
    pub name: String,
    pub picture: Option<String>,
    pub created_at: DateTime<Utc>,
    pub last_login: DateTime<Utc>,
}

// è¯„è®ºç›¸å…³çš„æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CommentAuthor {
    pub name: String,
    pub email: String,
    pub picture: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Comment {
    pub id: String,
    pub content: String,
    pub author: CommentAuthor,
    #[serde(rename = "createdAt")]
    pub created_at: DateTime<Utc>,
    pub timestamp: String,         // ç”¨äºå…¼å®¹å‰ç«¯
    pub parent_id: Option<String>, // çˆ¶è¯„è®ºIDï¼Œç”¨äºå›å¤åŠŸèƒ½
    pub upvotes: i32,              // ç‚¹èµæ•°
    pub downvotes: i32,            // ç‚¹è¸©æ•°
    pub user_vote: Option<String>, // å½“å‰ç”¨æˆ·çš„æŠ•ç¥¨çŠ¶æ€ ("up", "down", null)
    pub replies: Vec<Comment>,     // å›å¤åˆ—è¡¨
}

#[derive(Deserialize)]
pub struct CreateCommentPayload {
    pub content: String,
    pub author: CommentAuthor,
    pub parent_id: Option<String>, // çˆ¶è¯„è®ºID
}

#[derive(Deserialize)]
pub struct VotePayload {
    pub comment_id: String,
    pub vote_type: String, // "up", "down", "remove"
    pub user_email: String,
}

#[derive(Serialize)]
pub struct CommentsResponse {
    pub comments: Vec<Comment>,
}

#[derive(Serialize)]
pub struct VoteResponse {
    pub upvotes: i32,
    pub downvotes: i32,
    pub user_vote: Option<String>,
}
 mod.rs->->// ## src/database/mod.rs
pub mod init;
pub mod models;

pub use models::*;
 comments.rs->->// ## src/handlers/comments.rs
use crate::database::{Comment, CommentsResponse, CreateCommentPayload, VotePayload, VoteResponse};
use crate::handlers::DbPool;
use crate::services::{comment_service, vote_service};
use axum::{
    extract::{Query, State},
    http::StatusCode,
    Json,
};
use std::collections::HashMap;

pub async fn get_comments(
    State(pool): State<DbPool>,
    user_email: Option<Query<HashMap<String, String>>>,
) -> Result<Json<CommentsResponse>, (StatusCode, &'static str)> {
    println!("ğŸ“ è·å–è¯„è®ºåˆ—è¡¨");

    let current_user_email = user_email.and_then(|query| query.get("user_email").cloned());

    match comment_service::get_all_comments(&pool, current_user_email.as_deref()).await {
        Ok(comments) => {
            println!("âœ… è¿”å› {} æ¡è¯„è®º", comments.len());
            Ok(Json(CommentsResponse { comments }))
        }
        Err(e) => {
            eprintln!("âŒ è·å–è¯„è®ºå¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "è·å–è¯„è®ºå¤±è´¥"))
        }
    }
}

pub async fn create_comment(
    State(pool): State<DbPool>,
    Json(payload): Json<CreateCommentPayload>,
) -> Result<Json<Comment>, (StatusCode, &'static str)> {
    println!("ğŸ“ æ”¶åˆ°æ–°è¯„è®º: {} å­—ç¬¦", payload.content.len());

    // éªŒè¯è¯„è®ºå†…å®¹
    if let Err(msg) = comment_service::validate_comment_payload(&payload) {
        return Err((StatusCode::BAD_REQUEST, msg));
    }

    match comment_service::create_new_comment(&pool, payload).await {
        Ok(comment) => {
            let comment_type = if comment.parent_id.is_some() {
                "å›å¤"
            } else {
                "è¯„è®º"
            };
            println!(
                "âœ… {}å·²ä¿å­˜åˆ°æ•°æ®åº“: {} <{}> - {}",
                comment_type,
                comment.author.name,
                comment.author.email,
                &comment.content[..std::cmp::min(50, comment.content.len())]
            );
            Ok(Json(comment))
        }
        Err(e) => {
            eprintln!("âŒ åˆ›å»ºè¯„è®ºå¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "åˆ›å»ºè¯„è®ºå¤±è´¥"))
        }
    }
}

pub async fn handle_vote(
    State(pool): State<DbPool>,
    Json(payload): Json<VotePayload>,
) -> Result<Json<VoteResponse>, (StatusCode, &'static str)> {
    println!(
        "ğŸ—³ï¸ æ”¶åˆ°æŠ•ç¥¨è¯·æ±‚: {} - {}",
        payload.comment_id, payload.vote_type
    );

    // éªŒè¯æŠ•ç¥¨ç±»å‹
    if !["up", "down", "remove"].contains(&payload.vote_type.as_str()) {
        return Err((StatusCode::BAD_REQUEST, "æ— æ•ˆçš„æŠ•ç¥¨ç±»å‹"));
    }

    match vote_service::process_vote(&pool, payload).await {
        Ok(vote_response) => {
            println!(
                "âœ… æŠ•ç¥¨å·²æ›´æ–°: (+{} -{}) ç”¨æˆ·æŠ•ç¥¨: {:?}",
                vote_response.upvotes, vote_response.downvotes, vote_response.user_vote
            );
            Ok(Json(vote_response))
        }
        Err(e) => {
            eprintln!("âŒ å¤„ç†æŠ•ç¥¨å¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "å¤„ç†æŠ•ç¥¨å¤±è´¥"))
        }
    }
}
 mod.rs->->// ## src/handlers/mod.rs
pub mod auth;
pub mod comments;
pub mod health;

pub type DbPool = deadpool_postgres::Pool;
 auth.rs->->// ## src/handlers/auth.rs
use crate::database::{GoogleLoginPayload, User};
use crate::handlers::DbPool;
use crate::services::auth_service;
use axum::{extract::State, http::StatusCode, Json};

pub async fn handle_google_login(
    State(pool): State<DbPool>,
    Json(payload): Json<GoogleLoginPayload>,
) -> Result<Json<User>, (StatusCode, &'static str)> {
    println!("ğŸ”‘ æ”¶åˆ°ç™»å½•è¯·æ±‚ï¼ŒéªŒè¯ ID token...");

    match auth_service::authenticate_google_user(&pool, &payload.credential).await {
        Ok(user) => {
            println!("âœ… ç™»å½•æˆåŠŸ: {} <{}>", user.name, user.email);
            Ok(Json(user))
        }
        Err(e) => {
            eprintln!("âŒ ç™»å½•å¤±è´¥: {:?}", e);
            Err((StatusCode::UNAUTHORIZED, "ç™»å½•å¤±è´¥"))
        }
    }
}

pub async fn handle_google_logout() -> &'static str {
    println!("ğŸ‘‹ ç”¨æˆ·å·²ç™»å‡º");
    "ç™»å‡ºæˆåŠŸ"
}
 health.rs->->// # src/handlers/health.rs
pub async fn health_check() -> &'static str {
    "åç«¯æœåŠ¡è¿è¡Œæ­£å¸¸"
}
 auth_service.rs->->// ## src/services/auth_service.rs
use crate::database::{GoogleUserInfo, User};
use chrono::Utc;
use deadpool_postgres::Pool;

pub async fn authenticate_google_user(
    pool: &Pool,
    id_token: &str,
) -> Result<User, Box<dyn std::error::Error>> {
    // è°ƒç”¨ Google çš„ tokeninfo æ¥å£éªŒè¯ ID token
    let verify_url = format!(
        "https://oauth2.googleapis.com/tokeninfo?id_token={}",
        id_token
    );

    let response = reqwest::get(&verify_url).await?;

    if !response.status().is_success() {
        return Err("Invalid Google token".into());
    }

    let user_info: GoogleUserInfo = response.json().await?;

    // ä¿å­˜æˆ–æ›´æ–°ç”¨æˆ·ä¿¡æ¯
    save_or_update_user(pool, &user_info).await
}

async fn save_or_update_user(
    pool: &Pool,
    user_info: &GoogleUserInfo,
) -> Result<User, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let now = Utc::now();

    // é¦–å…ˆå°è¯•æ›´æ–°ç°æœ‰ç”¨æˆ·çš„æœ€åç™»å½•æ—¶é—´
    let rows_affected = client
        .execute(
            "UPDATE users SET last_login = $1, name = $2, picture = $3 
         WHERE google_id = $4",
            &[&now, &user_info.name, &user_info.picture, &user_info.sub],
        )
        .await?;

    if rows_affected == 0 {
        // ç”¨æˆ·ä¸å­˜åœ¨ï¼Œåˆ›å»ºæ–°ç”¨æˆ·
        client
            .execute(
                "INSERT INTO users (google_id, email, name, picture, created_at, last_login)
             VALUES ($1, $2, $3, $4, $5, $6)",
                &[
                    &user_info.sub,
                    &user_info.email,
                    &user_info.name,
                    &user_info.picture,
                    &now,
                    &now,
                ],
            )
            .await?;
    }

    // è·å–ç”¨æˆ·ä¿¡æ¯è¿”å›
    let row = client
        .query_one(
            "SELECT id, google_id, email, name, picture, created_at, last_login 
         FROM users WHERE google_id = $1",
            &[&user_info.sub],
        )
        .await?;

    Ok(User {
        id: row.get(0),
        google_id: row.get(1),
        email: row.get(2),
        name: row.get(3),
        picture: row.get(4),
        created_at: row.get(5),
        last_login: row.get(6),
    })
}
 mod.rs->->// ## src/services/mod.rs
pub mod auth_service;
pub mod comment_service;
pub mod vote_service;
 vote_service.rs->->// ## src/services/vote_service.rs
use crate::database::{VotePayload, VoteResponse};
use chrono::Utc;
use deadpool_postgres::Pool;

pub async fn get_comment_votes(
    pool: &Pool,
    comment_id: &str,
    user_email: Option<&str>,
) -> Result<(i32, i32, Option<String>), Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // è·å–æ€»æŠ•ç¥¨æ•°
    let row = client
        .query_one(
            "SELECT 
            SUM(CASE WHEN vote_type = 'up' THEN 1 ELSE 0 END) as upvotes,
            SUM(CASE WHEN vote_type = 'down' THEN 1 ELSE 0 END) as downvotes
         FROM comment_votes WHERE comment_id = $1",
            &[&comment_id],
        )
        .await?;

    let upvotes: i64 = row.get::<_, Option<i64>>(0).unwrap_or(0);
    let downvotes: i64 = row.get::<_, Option<i64>>(1).unwrap_or(0);

    // è·å–å½“å‰ç”¨æˆ·çš„æŠ•ç¥¨çŠ¶æ€
    let user_vote = if let Some(email) = user_email {
        match client
            .query_opt(
                "SELECT vote_type FROM comment_votes WHERE comment_id = $1 AND user_email = $2",
                &[&comment_id, &email],
            )
            .await?
        {
            Some(row) => Some(row.get::<_, String>(0)),
            None => None,
        }
    } else {
        None
    };

    Ok((upvotes as i32, downvotes as i32, user_vote))
}

pub async fn process_vote(
    pool: &Pool,
    payload: VotePayload,
) -> Result<VoteResponse, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // éªŒè¯è¯„è®ºæ˜¯å¦å­˜åœ¨
    let row = client
        .query_opt(
            "SELECT COUNT(*) FROM comments WHERE id = $1",
            &[&payload.comment_id],
        )
        .await?;
    if let Some(row) = row {
        let count: i64 = row.get(0);
        if count == 0 {
            return Err("è¯„è®ºä¸å­˜åœ¨".into());
        }
    }

    let now = Utc::now();

    // å¤„ç†æŠ•ç¥¨
    if payload.vote_type == "remove" {
        // ç§»é™¤æŠ•ç¥¨
        client
            .execute(
                "DELETE FROM comment_votes WHERE comment_id = $1 AND user_email = $2",
                &[&payload.comment_id, &payload.user_email],
            )
            .await?;
    } else {
        // æ’å…¥æˆ–æ›´æ–°æŠ•ç¥¨
        client
            .execute(
                "INSERT INTO comment_votes (comment_id, user_email, vote_type, created_at)
             VALUES ($1, $2, $3, $4)
             ON CONFLICT (comment_id, user_email) 
             DO UPDATE SET vote_type = EXCLUDED.vote_type, created_at = EXCLUDED.created_at",
                &[
                    &payload.comment_id,
                    &payload.user_email,
                    &payload.vote_type,
                    &now,
                ],
            )
            .await?;
    }

    // è·å–æ›´æ–°åçš„æŠ•ç¥¨ä¿¡æ¯
    let (upvotes, downvotes, user_vote) =
        get_comment_votes(pool, &payload.comment_id, Some(&payload.user_email)).await?;

    Ok(VoteResponse {
        upvotes,
        downvotes,
        user_vote,
    })
}
 comment_service.rs->->// ## src/services/comment_service.rs
use crate::database::{Comment, CommentAuthor, CreateCommentPayload};
use crate::services::vote_service;
use chrono::Utc;
use deadpool_postgres::Pool;
use uuid::Uuid;

pub fn validate_comment_payload(payload: &CreateCommentPayload) -> Result<(), &'static str> {
    let content = payload.content.trim();
    if content.is_empty() {
        return Err("è¯„è®ºå†…å®¹ä¸èƒ½ä¸ºç©º");
    }
    if content.len() > 500 {
        return Err("è¯„è®ºå†…å®¹ä¸èƒ½è¶…è¿‡500å­—ç¬¦");
    }
    if payload.author.name.trim().is_empty() || payload.author.email.trim().is_empty() {
        return Err("ç”¨æˆ·ä¿¡æ¯ä¸å®Œæ•´");
    }
    Ok(())
}

pub async fn get_all_comments(
    pool: &Pool,
    user_email: Option<&str>,
) -> Result<Vec<Comment>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT id, content, author_name, author_email, author_picture, created_at, parent_id 
         FROM comments ORDER BY created_at ASC",
            &[],
        )
        .await?;

    let mut comments = Vec::new();

    for row in rows {
        let created_at = row.get(5);
        let mut comment = Comment {
            id: row.get(0),
            content: row.get(1),
            author: CommentAuthor {
                name: row.get(2),
                email: row.get(3),
                picture: row.get(4),
            },
            created_at,
            timestamp: created_at.to_rfc3339(),
            parent_id: row.get(6),
            upvotes: 0,
            downvotes: 0,
            user_vote: None,
            replies: Vec::new(),
        };

        // è·å–æŠ•ç¥¨ä¿¡æ¯
        if let Ok((upvotes, downvotes, user_vote)) =
            vote_service::get_comment_votes(pool, &comment.id, user_email).await
        {
            comment.upvotes = upvotes;
            comment.downvotes = downvotes;
            comment.user_vote = user_vote;
        }

        comments.push(comment);
    }

    Ok(comments)
}

pub async fn create_new_comment(
    pool: &Pool,
    payload: CreateCommentPayload,
) -> Result<Comment, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // å¦‚æœæ˜¯å›å¤ï¼ŒéªŒè¯çˆ¶è¯„è®ºæ˜¯å¦å­˜åœ¨
    if let Some(parent_id) = &payload.parent_id {
        let row = client
            .query_opt("SELECT COUNT(*) FROM comments WHERE id = $1", &[parent_id])
            .await?;
        if let Some(row) = row {
            let count: i64 = row.get(0);
            if count == 0 {
                return Err("çˆ¶è¯„è®ºä¸å­˜åœ¨".into());
            }
        }
    }

    let now = Utc::now();
    let comment_id = Uuid::new_v4().to_string();
    let content = payload.content.trim();

    // ä¿å­˜è¯„è®ºåˆ°æ•°æ®åº“
    client.execute(
        "INSERT INTO comments (id, content, author_name, author_email, author_picture, created_at, parent_id)
         VALUES ($1, $2, $3, $4, $5, $6, $7)",
        &[
            &comment_id,
            &content,
            &payload.author.name,
            &payload.author.email,
            &payload.author.picture,
            &now,
            &payload.parent_id,
        ],
    ).await?;

    Ok(Comment {
        id: comment_id,
        content: content.to_string(),
        author: payload.author,
        created_at: now,
        timestamp: now.to_rfc3339(),
        parent_id: payload.parent_id,
        upvotes: 0,
        downvotes: 0,
        user_vote: None,
        replies: Vec::new(),
    })
}
 cors.rs->->// ## src/utils/cors.rs
use axum::http::{header, HeaderValue, Method};
use tower_http::cors::CorsLayer;

pub fn create_cors_layer() -> CorsLayer {
    CorsLayer::new()
        .allow_origin([
            HeaderValue::from_static("http://localhost:5173"),
            HeaderValue::from_static("http://localhost:5174"),
            HeaderValue::from_static("http://127.0.0.1:5173"),
            HeaderValue::from_static("http://127.0.0.1:5174"),
            HeaderValue::from_static("https://btc.apin.app"),
            HeaderValue::from_static("https://www.btc.apin.app"),
            HeaderValue::from_static("https://www.apin.app"),
            HeaderValue::from_static("https://apin.app"),
            HeaderValue::from_static("https://fly.apin.app"),
            HeaderValue::from_static("https://test.apin.app"),
            HeaderValue::from_static("https://web-btc.fly.dev"),
        ])
        .allow_methods([Method::GET, Method::POST, Method::OPTIONS])
        .allow_headers([header::CONTENT_TYPE, header::AUTHORIZATION])
}
 mod.rs->->// ## src/utils/mod.rs
pub mod cors;

### ç³»ç»Ÿ:
æˆ‘æ¥å¸®ä½ ä¸ºè¿™ä¸ªé¡¹ç›®æ·»åŠ æ–‡ç« ç®¡ç†åŠŸèƒ½å’Œ GraphQL ç‰¹æ€§ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦æ›´æ–°ä¾èµ–é¡¹ï¼Œç„¶åæ·»åŠ ç›¸åº”çš„æ¨¡å—ã€‚ ä»£ç 
```toml
[package]
name = "blog-api"
version = "0.1.0"
edition = "2021"

[dependencies]
# Web æ¡†æ¶
axum = { version = "0.7", features = ["macros"] }
tokio = { version = "1.0", features = ["full"] }
tower = "0.4"
tower-http = { version = "0.5", features = ["cors"] }

# æ•°æ®åº“
deadpool-postgres = "0.14"
tokio-postgres = { version = "0.7", features = ["with-chrono-0_4", "with-uuid-1"] }

# GraphQL
async-graphql = { version = "7.0", features = ["chrono", "uuid"] }
async-graphql-axum = "7.0"

# åºåˆ—åŒ–
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# æ—¥æœŸæ—¶é—´
chrono = { version = "0.4", features = ["serde"] }

# UUID
uuid = { version = "1.0", features = ["v4", "serde"] }

# HTTP å®¢æˆ·ç«¯
reqwest = { version = "0.12", features = ["json"] }

# ç¯å¢ƒå˜é‡
dotenv = "0.15"

# é”™è¯¯å¤„ç†
anyhow = "1.0"
thiserror = "1.0"
```
 ä»£ç 
```rust
// ## src/database/init.rs
use deadpool_postgres::Pool;

pub async fn init_database(pool: &Pool) -> Result<(), Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // åˆ›å»ºç”¨æˆ·è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS users (
            id BIGSERIAL PRIMARY KEY,
            google_id TEXT UNIQUE NOT NULL,
            email TEXT NOT NULL,
            name TEXT NOT NULL,
            picture TEXT,
            created_at TIMESTAMPTZ NOT NULL,
            last_login TIMESTAMPTZ NOT NULL
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºåˆ†ç±»è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS categories (
            id BIGSERIAL PRIMARY KEY,
            name TEXT UNIQUE NOT NULL,
            description TEXT,
            slug TEXT UNIQUE NOT NULL,
            created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºæ ‡ç­¾è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS tags (
            id BIGSERIAL PRIMARY KEY,
            name TEXT UNIQUE NOT NULL,
            slug TEXT UNIQUE NOT NULL,
            created_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºæ–‡ç« è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS articles (
            id TEXT PRIMARY KEY,
            title TEXT NOT NULL,
            slug TEXT UNIQUE NOT NULL,
            content TEXT NOT NULL,
            excerpt TEXT,
            image_url TEXT,
            category_id BIGINT REFERENCES categories(id),
            author_id BIGINT NOT NULL REFERENCES users(id),
            status TEXT NOT NULL DEFAULT 'draft' CHECK (status IN ('draft', 'published', 'archived')),
            view_count BIGINT NOT NULL DEFAULT 0,
            created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
            updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
            published_at TIMESTAMPTZ
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºæ–‡ç« æ ‡ç­¾å…³è”è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS article_tags (
            article_id TEXT NOT NULL REFERENCES articles(id) ON DELETE CASCADE,
            tag_id BIGINT NOT NULL REFERENCES tags(id) ON DELETE CASCADE,
            PRIMARY KEY (article_id, tag_id)
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºè¯„è®ºè¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS comments (
            id TEXT PRIMARY KEY,
            content TEXT NOT NULL,
            author_name TEXT NOT NULL,
            author_email TEXT NOT NULL,
            author_picture TEXT NOT NULL,
            parent_id TEXT NULL,
            article_id TEXT NULL REFERENCES articles(id) ON DELETE CASCADE,
            created_at TIMESTAMPTZ NOT NULL,
            FOREIGN KEY (parent_id) REFERENCES comments (id) ON DELETE CASCADE
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºæŠ•ç¥¨è¡¨
    client
        .execute(
            "CREATE TABLE IF NOT EXISTS comment_votes (
            id BIGSERIAL PRIMARY KEY,
            comment_id TEXT NOT NULL,
            user_email TEXT NOT NULL,
            vote_type TEXT NOT NULL CHECK (vote_type IN ('up', 'down')),
            created_at TIMESTAMPTZ NOT NULL,
            UNIQUE(comment_id, user_email),
            FOREIGN KEY (comment_id) REFERENCES comments (id) ON DELETE CASCADE
        )",
            &[],
        )
        .await?;

    // åˆ›å»ºç´¢å¼•
    create_indexes(&client).await?;

    // æ’å…¥é»˜è®¤æ•°æ®
    insert_default_data(&client).await?;

    Ok(())
}

async fn create_indexes(client: &tokio_postgres::Client) -> Result<(), tokio_postgres::Error> {
    let indexes = [
        // åŸæœ‰ç´¢å¼•
        "CREATE INDEX IF NOT EXISTS idx_comments_created_at ON comments (created_at DESC)",
        "CREATE INDEX IF NOT EXISTS idx_comments_parent_id ON comments (parent_id)",
        "CREATE INDEX IF NOT EXISTS idx_users_google_id ON users (google_id)",
        "CREATE INDEX IF NOT EXISTS idx_users_email ON users (email)",
        "CREATE INDEX IF NOT EXISTS idx_votes_comment_user ON comment_votes (comment_id, user_email)",
        
        // æ–‡ç« ç›¸å…³ç´¢å¼•
        "CREATE INDEX IF NOT EXISTS idx_articles_status ON articles (status)",
        "CREATE INDEX IF NOT EXISTS idx_articles_category ON articles (category_id)",
        "CREATE INDEX IF NOT EXISTS idx_articles_author ON articles (author_id)",
        "CREATE INDEX IF NOT EXISTS idx_articles_created_at ON articles (created_at DESC)",
        "CREATE INDEX IF NOT EXISTS idx_articles_published_at ON articles (published_at DESC)",
        "CREATE INDEX IF NOT EXISTS idx_articles_slug ON articles (slug)",
        "CREATE INDEX IF NOT EXISTS idx_categories_slug ON categories (slug)",
        "CREATE INDEX IF NOT EXISTS idx_tags_slug ON tags (slug)",
        "CREATE INDEX IF NOT EXISTS idx_comments_article ON comments (article_id)",
    ];

    for &index_sql in &indexes {
        client.execute(index_sql, &[]).await?;
    }

    Ok(())
}

async fn insert_default_data(client: &tokio_postgres::Client) -> Result<(), tokio_postgres::Error> {
    // æ’å…¥é»˜è®¤åˆ†ç±»
    let default_categories = [
        ("æŠ€æœ¯", "Technology", "technology", "æŠ€æœ¯ç›¸å…³çš„æ–‡ç« "),
        ("ç”Ÿæ´»", "Life", "life", "ç”Ÿæ´»æ„Ÿæ‚Ÿå’Œæ—¥å¸¸åˆ†äº«"),
        ("éšç¬”", "Essays", "essays", "éšç¬”æ‚è°ˆ"),
    ];

    for (name, _en_name, slug, description) in &default_categories {
        client
            .execute(
                "INSERT INTO categories (name, slug, description) 
                 VALUES ($1, $2, $3) 
                 ON CONFLICT (slug) DO NOTHING",
                &[name, slug, description],
            )
            .await?;
    }

    // æ’å…¥é»˜è®¤æ ‡ç­¾
    let default_tags = [
        ("Rust", "rust"),
        ("JavaScript", "javascript"),
        ("Python", "python"),
        ("Webå¼€å‘", "web-development"),
        ("æ•°æ®åº“", "database"),
        ("å‰ç«¯", "frontend"),
        ("åç«¯", "backend"),
        ("æ•™ç¨‹", "tutorial"),
        ("ç»éªŒåˆ†äº«", "experience"),
    ];

    for (name, slug) in &default_tags {
        client
            .execute(
                "INSERT INTO tags (name, slug) 
                 VALUES ($1, $2) 
                 ON CONFLICT (slug) DO NOTHING",
                &[name, slug],
            )
            .await?;
    }

    Ok(())
}
```
 ä»£ç 
```rust
// ## src/database/models.rs
use async_graphql::*;
use chrono::{DateTime, Utc};
use serde::{Deserialize, Serialize};

// å‰ç«¯å‘é€çš„æ•°æ®æ ¼å¼
#[derive(Deserialize)]
pub struct GoogleLoginPayload {
    pub credential: String, // ID token
}

// è§£æ Google è¿”å›çš„ token ä¿¡æ¯
#[derive(Debug, Deserialize)]
pub struct GoogleUserInfo {
    pub email: String,
    pub name: String,
    #[allow(dead_code)]
    pub picture: Option<String>,
    pub sub: String, // ç”¨æˆ·å”¯ä¸€æ ‡è¯†
}

// ç”¨æˆ·æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, SimpleObject)]
#[graphql(complex)]
pub struct User {
    pub id: i64,
    pub google_id: String,
    pub email: String,
    pub name: String,
    pub picture: Option<String>,
    pub created_at: DateTime<Utc>,
    pub last_login: DateTime<Utc>,
}

#[ComplexObject]
impl User {
    async fn articles(&self, ctx: &Context<'_>) -> FieldResult<Vec<Article>> {
        // è¿™é‡Œå¯ä»¥å®ç°è·å–ç”¨æˆ·æ–‡ç« çš„é€»è¾‘
        // æš‚æ—¶è¿”å›ç©ºæ•°ç»„
        Ok(vec![])
    }
}

// åˆ†ç±»æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, SimpleObject)]
#[graphql(complex)]
pub struct Category {
    pub id: i64,
    pub name: String,
    pub slug: String,
    pub description: Option<String>,
    pub created_at: DateTime<Utc>,
}

#[ComplexObject]
impl Category {
    async fn articles(&self, ctx: &Context<'_>) -> FieldResult<Vec<Article>> {
        // å®ç°è·å–åˆ†ç±»ä¸‹çš„æ–‡ç« 
        Ok(vec![])
    }

    async fn article_count(&self, ctx: &Context<'_>) -> FieldResult<i32> {
        // å®ç°è·å–åˆ†ç±»ä¸‹çš„æ–‡ç« æ•°é‡
        Ok(0)
    }
}

// æ ‡ç­¾æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, SimpleObject)]
#[graphql(complex)]
pub struct Tag {
    pub id: i64,
    pub name: String,
    pub slug: String,
    pub created_at: DateTime<Utc>,
}

#[ComplexObject]
impl Tag {
    async fn articles(&self, ctx: &Context<'_>) -> FieldResult<Vec<Article>> {
        // å®ç°è·å–æ ‡ç­¾ä¸‹çš„æ–‡ç« 
        Ok(vec![])
    }

    async fn article_count(&self, ctx: &Context<'_>) -> FieldResult<i32> {
        // å®ç°è·å–æ ‡ç­¾ä¸‹çš„æ–‡ç« æ•°é‡
        Ok(0)
    }
}

// æ–‡ç« çŠ¶æ€æšä¸¾
#[derive(Debug, Clone, Serialize, Deserialize, Enum, Copy, PartialEq, Eq)]
pub enum ArticleStatus {
    Draft,
    Published,
    Archived,
}

impl From<String> for ArticleStatus {
    fn from(s: String) -> Self {
        match s.as_str() {
            "published" => ArticleStatus::Published,
            "archived" => ArticleStatus::Archived,
            _ => ArticleStatus::Draft,
        }
    }
}

impl From<ArticleStatus> for String {
    fn from(status: ArticleStatus) -> Self {
        match status {
            ArticleStatus::Draft => "draft".to_string(),
            ArticleStatus::Published => "published".to_string(),
            ArticleStatus::Archived => "archived".to_string(),
        }
    }
}

// æ–‡ç« æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize, SimpleObject)]
#[graphql(complex)]
pub struct Article {
    pub id: String,
    pub title: String,
    pub slug: String,
    pub content: String,
    pub excerpt: Option<String>,
    pub image_url: Option<String>,
    pub status: ArticleStatus,
    pub view_count: i64,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
    pub published_at: Option<DateTime<Utc>>,
}

#[ComplexObject]
impl Article {
    async fn author(&self, ctx: &Context<'_>) -> FieldResult<Option<User>> {
        // å®ç°è·å–æ–‡ç« ä½œè€…
        Ok(None)
    }

    async fn category(&self, ctx: &Context<'_>) -> FieldResult<Option<Category>> {
        // å®ç°è·å–æ–‡ç« åˆ†ç±»
        Ok(None)
    }

    async fn tags(&self, ctx: &Context<'_>) -> FieldResult<Vec<Tag>> {
        // å®ç°è·å–æ–‡ç« æ ‡ç­¾
        Ok(vec![])
    }

    async fn comments(&self, ctx: &Context<'_>) -> FieldResult<Vec<Comment>> {
        // å®ç°è·å–æ–‡ç« è¯„è®º
        Ok(vec![])
    }

    async fn comment_count(&self, ctx: &Context<'_>) -> FieldResult<i32> {
        // å®ç°è·å–è¯„è®ºæ•°é‡
        Ok(0)
    }
}

// GraphQL è¾“å…¥ç±»å‹
#[derive(InputObject)]
pub struct CreateArticleInput {
    pub title: String,
    pub content: String,
    pub excerpt: Option<String>,
    pub image_url: Option<String>,
    pub category_id: Option<i64>,
    pub tag_ids: Option<Vec<i64>>,
    pub status: Option<ArticleStatus>,
}

#[derive(InputObject)]
pub struct UpdateArticleInput {
    pub title: Option<String>,
    pub content: Option<String>,
    pub excerpt: Option<String>,
    pub image_url: Option<String>,
    pub category_id: Option<i64>,
    pub tag_ids: Option<Vec<i64>>,
    pub status: Option<ArticleStatus>,
}

#[derive(InputObject)]
pub struct CreateCategoryInput {
    pub name: String,
    pub slug: String,
    pub description: Option<String>,
}

#[derive(InputObject)]
pub struct CreateTagInput {
    pub name: String,
    pub slug: String,
}

#[derive(InputObject)]
pub struct ArticleFilter {
    pub status: Option<ArticleStatus>,
    pub category_id: Option<i64>,
    pub tag_ids: Option<Vec<i64>>,
    pub author_id: Option<i64>,
    pub search: Option<String>,
}

#[derive(InputObject)]
pub struct Pagination {
    pub page: Option<i32>,
    pub per_page: Option<i32>,
}

#[derive(SimpleObject)]
pub struct ArticleConnection {
    pub articles: Vec<Article>,
    pub total: i32,
    pub page: i32,
    pub per_page: i32,
    pub total_pages: i32,
}

// è¯„è®ºç›¸å…³çš„æ•°æ®ç»“æ„
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CommentAuthor {
    pub name: String,
    pub email: String,
    pub picture: String,
}

#[derive(Debug, Clone, Serialize, Deserialize, SimpleObject)]
#[graphql(complex)]
pub struct Comment {
    pub id: String,
    pub content: String,
    pub author: CommentAuthor,
    #[serde(rename = "createdAt")]
    pub created_at: DateTime<Utc>,
    pub timestamp: String,         // ç”¨äºå…¼å®¹å‰ç«¯
    pub parent_id: Option<String>, // çˆ¶è¯„è®ºIDï¼Œç”¨äºå›å¤åŠŸèƒ½
    pub article_id: Option<String>, // æ–‡ç« ID
    pub upvotes: i32,              // ç‚¹èµæ•°
    pub downvotes: i32,            // ç‚¹è¸©æ•°
    pub user_vote: Option<String>, // å½“å‰ç”¨æˆ·çš„æŠ•ç¥¨çŠ¶æ€ ("up", "down", null)
    pub replies: Vec<Comment>,     // å›å¤åˆ—è¡¨
}

#[ComplexObject]
impl Comment {
    async fn article(&self, ctx: &Context<'_>) -> FieldResult<Option<Article>> {
        // å®ç°è·å–è¯„è®ºæ‰€å±æ–‡ç« 
        Ok(None)
    }
}

#[derive(Deserialize)]
pub struct CreateCommentPayload {
    pub content: String,
    pub author: CommentAuthor,
    pub parent_id: Option<String>, // çˆ¶è¯„è®ºID
    pub article_id: Option<String>, // æ–‡ç« ID
}

#[derive(Deserialize)]
pub struct VotePayload {
    pub comment_id: String,
    pub vote_type: String, // "up", "down", "remove"
    pub user_email: String,
}

#[derive(Serialize)]
pub struct CommentsResponse {
    pub comments: Vec<Comment>,
}

#[derive(Serialize)]
pub struct VoteResponse {
    pub upvotes: i32,
    pub downvotes: i32,
    pub user_vote: Option<String>,
}

// REST API å“åº”ç±»å‹
#[derive(Serialize)]
pub struct ArticleResponse {
    pub article: Article,
}

#[derive(Serialize)]
pub struct ArticlesResponse {
    pub articles: Vec<Article>,
    pub total: i32,
    pub page: i32,
    pub per_page: i32,
}

#[derive(Serialize)]
pub struct CategoriesResponse {
    pub categories: Vec<Category>,
}

#[derive(Serialize)]
pub struct TagsResponse {
    pub tags: Vec<Tag>,
}
```
 ä»£ç 
```rust
// ## src/graphql/schema.rs
use async_graphql::*;
use deadpool_postgres::Pool;

use crate::database::*;
use crate::services::{article_service, category_service, tag_service};

pub type BlogSchema = Schema<QueryRoot, MutationRoot, EmptySubscription>;

// GraphQL Context
pub struct GraphQLContext {
    pub pool: Pool,
    pub current_user: Option<User>,
}

impl GraphQLContext {
    pub fn new(pool: Pool, current_user: Option<User>) -> Self {
        Self { pool, current_user }
    }
}

// Query Root
pub struct QueryRoot;

#[Object]
impl QueryRoot {
    // æ–‡ç« æŸ¥è¯¢
    async fn articles(
        &self,
        ctx: &Context<'_>,
        filter: Option<ArticleFilter>,
        pagination: Option<Pagination>,
    ) -> FieldResult<ArticleConnection> {
        let context = ctx.data::<GraphQLContext>()?;
        let filter = filter.unwrap_or_default();
        let pagination = pagination.unwrap_or_default();
        
        let page = pagination.page.unwrap_or(1).max(1);
        let per_page = pagination.per_page.unwrap_or(10).max(1).min(100);
        
        let result = article_service::get_articles_paginated(
            &context.pool,
            &filter,
            page,
            per_page,
        ).await?;
        
        Ok(result)
    }

    async fn article(&self, ctx: &Context<'_>, id: Option<String>, slug: Option<String>) -> FieldResult<Option<Article>> {
        let context = ctx.data::<GraphQLContext>()?;
        
        if let Some(id) = id {
            Ok(article_service::get_article_by_id(&context.pool, &id).await?)
        } else if let Some(slug) = slug {
            Ok(article_service::get_article_by_slug(&context.pool, &slug).await?)
        } else {
            Err("å¿…é¡»æä¾› id æˆ– slug å‚æ•°".into())
        }
    }

    // åˆ†ç±»æŸ¥è¯¢
    async fn categories(&self, ctx: &Context<'_>) -> FieldResult<Vec<Category>> {
        let context = ctx.data::<GraphQLContext>()?;
        Ok(category_service::get_all_categories(&context.pool).await?)
    }

    async fn category(&self, ctx: &Context<'_>, id: Option<i64>, slug: Option<String>) -> FieldResult<Option<Category>> {
        let context = ctx.data::<GraphQLContext>()?;
        
        if let Some(id) = id {
            Ok(category_service::get_category_by_id(&context.pool, id).await?)
        } else if let Some(slug) = slug {
            Ok(category_service::get_category_by_slug(&context.pool, &slug).await?)
        } else {
            Err("å¿…é¡»æä¾› id æˆ– slug å‚æ•°".into())
        }
    }

    // æ ‡ç­¾æŸ¥è¯¢
    async fn tags(&self, ctx: &Context<'_>) -> FieldResult<Vec<Tag>> {
        let context = ctx.data::<GraphQLContext>()?;
        Ok(tag_service::get_all_tags(&context.pool).await?)
    }

    async fn tag(&self, ctx: &Context<'_>, id: Option<i64>, slug: Option<String>) -> FieldResult<Option<Tag>> {
        let context = ctx.data::<GraphQLContext>()?;
        
        if let Some(id) = id {
            Ok(tag_service::get_tag_by_id(&context.pool, id).await?)
        } else if let Some(slug) = slug {
            Ok(tag_service::get_tag_by_slug(&context.pool, &slug).await?)
        } else {
            Err("å¿…é¡»æä¾› id æˆ– slug å‚æ•°".into())
        }
    }

    // æœç´¢
    async fn search_articles(
        &self,
        ctx: &Context<'_>,
        query: String,
        pagination: Option<Pagination>,
    ) -> FieldResult<ArticleConnection> {
        let context = ctx.data::<GraphQLContext>()?;
        let pagination = pagination.unwrap_or_default();
        
        let page = pagination.page.unwrap_or(1).max(1);
        let per_page = pagination.per_page.unwrap_or(10).max(1).min(100);
        
        let filter = ArticleFilter {
            search: Some(query),
            ..Default::default()
        };
        
        let result = article_service::get_articles_paginated(
            &context.pool,
            &filter,
            page,
            per_page,
        ).await?;
        
        Ok(result)
    }
}

// Mutation Root
pub struct MutationRoot;

#[Object]
impl MutationRoot {
    // æ–‡ç« æ“ä½œ
    async fn create_article(
        &self,
        ctx: &Context<'_>,
        input: CreateArticleInput,
    ) -> FieldResult<Article> {
        let context = ctx.data::<GraphQLContext>()?;
        
        let user = context.current_user.as_ref()
            .ok_or("éœ€è¦ç™»å½•æ‰èƒ½åˆ›å»ºæ–‡ç« ")?;
            
        Ok(article_service::create_article(&context.pool, input, user.id).await?)
    }

    async fn update_article(
        &self,
        ctx: &Context<'_>,
        id: String,
        input: UpdateArticleInput,
    ) -> FieldResult<Article> {
        let context = ctx.data::<GraphQLContext>()?;
        
        let user = context.current_user.as_ref()
            .ok_or("éœ€è¦ç™»å½•æ‰èƒ½æ›´æ–°æ–‡ç« ")?;
            
        Ok(article_service::update_article(&context.pool, &id, input, user.id).await?)
    }

    async fn delete_article(&self, ctx: &Context<'_>, id: String) -> FieldResult<bool> {
        let context = ctx.data::<GraphQLContext>()?;
        
        let user = context.current_user.as_ref()
            .ok_or("éœ€è¦ç™»å½•æ‰èƒ½åˆ é™¤æ–‡ç« ")?;
            
        Ok(article_service::delete_article(&context.pool, &id, user.id).await?)
    }

    async fn publish_article(&self, ctx: &Context<'_>, id: String) -> FieldResult<Article> {
        let context = ctx.data::<GraphQLContext>()?;
        
        let user = context.current_user.as_ref()
            .ok_or("éœ€è¦ç™»å½•æ‰èƒ½å‘å¸ƒæ–‡ç« ")?;
            
        Ok(article_service::publish_article(&context.pool, &id, user.id).await?)
    }

    // åˆ†ç±»æ“ä½œ
    async fn create_category(
        &self,
        ctx: &Context<'_>,
        input: CreateCategoryInput,
    ) -> FieldResult<Category> {
        let context = ctx.data::<GraphQLContext>()?;
        
        context.current_user.as_ref()
            .ok_or("éœ€è¦ç™»å½•æ‰èƒ½åˆ›å»ºåˆ†ç±»")?;
            
        Ok(category_service::create_category(&context.pool, input).await?)
    }

    // æ ‡ç­¾æ“ä½œ
    async fn create_tag(
        &self,
        ctx: &Context<'_>,
        input: CreateTagInput,
    ) -> FieldResult<Tag> {
        let context = ctx.data::<GraphQLContext>()?;
        
        context.current_user.as_ref()
            .ok_or("éœ€è¦ç™»å½•æ‰èƒ½åˆ›å»ºæ ‡ç­¾")?;
            
        Ok(tag_service::create_tag(&context.pool, input).await?)
    }
}

// é»˜è®¤å®ç°
impl Default for ArticleFilter {
    fn default() -> Self {
        Self {
            status: None,
            category_id: None,
            tag_ids: None,
            author_id: None,
            search: None,
        }
    }
}

impl Default for Pagination {
    fn default() -> Self {
        Self {
            page: Some(1),
            per_page: Some(10),
        }
    }
}

pub fn create_schema(pool: Pool) -> BlogSchema {
    Schema::build(QueryRoot, MutationRoot, EmptySubscription)
        .data(pool)
        .finish()
}
```
 ä»£ç 
```rust
// ## src/graphql/mod.rs
pub mod schema;

pub use schema::*;
```
 ä»£ç 
```rust
// ## src/services/article_service.rs
use crate::database::*;
use chrono::Utc;
use deadpool_postgres::Pool;
use uuid::Uuid;

pub async fn get_articles_paginated(
    pool: &Pool,
    filter: &ArticleFilter,
    page: i32,
    per_page: i32,
) -> Result<ArticleConnection, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let offset = (page - 1) * per_page;

    // æ„å»ºæŸ¥è¯¢æ¡ä»¶
    let mut where_clauses = vec!["1=1".to_string()];
    let mut params: Vec<&(dyn tokio_postgres::types::ToSql + Sync)> = vec![];
    let mut param_count = 0;

    // çŠ¶æ€è¿‡æ»¤
    if let Some(status) = &filter.status {
        param_count += 1;
        where_clauses.push(format!("a.status = ${}", param_count));
        params.push(&String::from(*status));
    }

    // åˆ†ç±»è¿‡æ»¤
    if let Some(category_id) = filter.category_id {
        param_count += 1;
        where_clauses.push(format!("a.category_id = ${}", param_count));
        params.push(&category_id);
    }

    // ä½œè€…è¿‡æ»¤
    if let Some(author_id) = filter.author_id {
        param_count += 1;
        where_clauses.push(format!("a.author_id = ${}", param_count));
        params.push(&author_id);
    }

    // æœç´¢è¿‡æ»¤
    if let Some(search) = &filter.search {
        param_count += 1;
        where_clauses.push(format!(
            "(a.title ILIKE ${} OR a.content ILIKE ${} OR a.excerpt ILIKE ${})",
            param_count, param_count, param_count
        ));
        let search_pattern = format!("%{}%", search);
        params.push(&search_pattern);
    }

    let where_clause = where_clauses.join(" AND ");

    // æŸ¥è¯¢æ€»æ•°
    let count_query = format!(
        "SELECT COUNT(*) FROM articles a WHERE {}",
        where_clause
    );
    let total_row = client.query_one(&count_query, &params).await?;
    let total: i64 = total_row.get(0);

    // æŸ¥è¯¢æ–‡ç« 
    param_count += 1;
    params.push(&per_page);
    param_count += 1;
    params.push(&offset);

    let query = format!(
        "SELECT a.id, a.title, a.slug, a.content, a.excerpt, a.image_url, 
                a.status, a.view_count, a.created_at, a.updated_at, a.published_at
         FROM articles a 
         WHERE {} 
         ORDER BY COALESCE(a.published_at, a.created_at) DESC 
         LIMIT ${} OFFSET ${}",
        where_clause, param_count - 1, param_count
    );

    let rows = client.query(&query, &params).await?;
    let mut articles = Vec::new();

    for row in rows {
        let status_str: String = row.get(6);
        articles.push(Article {
            id: row.get(0),
            title: row.get(1),
            slug: row.get(2),
            content: row.get(3),
            excerpt: row.get(4),
            image_url: row.get(5),
            status: ArticleStatus::from(status_str),
            view_count: row.get(7),
            created_at: row.get(8),
            updated_at: row.get(9),
            published_at: row.get(10),
        });
    }

    let total_pages = ((total as f64) / (per_page as f64)).ceil() as i32;

    Ok(ArticleConnection {
        articles,
        total: total as i32,
        page,
        per_page,
        total_pages,
    })
}

pub async fn get_article_by_id(
    pool: &Pool,
    id: &str,
) -> Result<Option<Article>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    
    let row = client
        .query_opt(
            "SELECT id, title, slug, content, excerpt, image_url, status, view_count,
                    created_at, updated_at, published_at
             FROM articles WHERE id = $1",
            &[&id],
        )
        .await?;

    if let Some(row) = row {
        let status_str: String = row.get(6);
        Ok(Some(Article {
            id: row.get(0),
            title: row.get(1),
            slug: row.get(2),
            content: row.get(3),
            excerpt: row.get(4),
            image_url: row.get(5),
            status: ArticleStatus::from(status_str),
            view_count: row.get(7),
            created_at: row.get(8),
            updated_at: row.get(9),
            published_at: row.get(10),
        }))
    } else {
        Ok(None)
    }
}

pub async fn get_article_by_slug(
    pool: &Pool,
    slug: &str,
) -> Result<Option<Article>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    
    let row = client
        .query_opt(
            "SELECT id, title, slug, content, excerpt, image_url, status, view_count,
                    created_at, updated_at, published_at
             FROM articles WHERE slug = $1",
            &[&slug],
        )
        .await?;

    if let Some(row) = row {
        let status_str: String = row.get(6);
        Ok(Some(Article {
            id: row.get(0),
            title: row.get(1),
            slug: row.get(2),
            content: row.get(3),
            excerpt: row.get(4),
            image_url: row.get(5),
            status: ArticleStatus::from(status_str),
            view_count: row.get(7),
            created_at: row.get(8),
            updated_at: row.get(9),
            published_at: row.get(10),
        }))
    } else {
        Ok(None)
    }
}

pub async fn create_article(
    pool: &Pool,
    input: CreateArticleInput,
    author_id: i64,
) -> Result<Article, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let now = Utc::now();
    let article_id = Uuid::new_v4().to_string();
    
    // ç”Ÿæˆ slug
    let slug = generate_slug(&input.title);
    
    // æ£€æŸ¥ slug æ˜¯å¦å”¯ä¸€
    let unique_slug = ensure_unique_slug(pool, &slug).await?;
    
    let status = input.status.unwrap_or(ArticleStatus::Draft);
    let status_str = String::from(status);
    
    let published_at = if status == ArticleStatus::Published {
        Some(now)
    } else {
        None
    };

    // æ’å…¥æ–‡ç« 
    client
        .execute(
            "INSERT INTO articles (id, title, slug, content, excerpt, image_url, 
                                  category_id, author_id, status, created_at, updated_at, published_at)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)",
            &[
                &article_id,
                &input.title,
                &unique_slug,
                &input.content,
                &input.excerpt,
                &input.image_url,
                &input.category_id,
                &author_id,
                &status_str,
                &now,
                &now,
                &published_at,
            ],
        )
        .await?;

    // å…³è”æ ‡ç­¾
    if let Some(tag_ids) = input.tag_ids {
        for tag_id in tag_ids {
            client
                .execute(
                    "INSERT INTO article_tags (article_id, tag_id) VALUES ($1, $2)",
                    &[&article_id, &tag_id],
                )
                .await?;
        }
    }

    Ok(Article {
        id: article_id,
        title: input.title,
        slug: unique_slug,
        content: input.content,
        excerpt: input.excerpt,
        image_url: input.image_url,
        status,
        view_count: 0,
        created_at: now,
        updated_at: now,
        published_at,
    })
}

pub async fn update_article(
    pool: &Pool,
    id: &str,
    input: UpdateArticleInput,
    author_id: i64,
) -> Result<Article, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let now = Utc::now();

    // æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    let row = client
        .query_opt(
            "SELECT author_id FROM articles WHERE id = $1",
            &[&id],
        )
        .await?;

    if let Some(row) = row {
        let article_author_id: i64 = row.get(0);
        if article_author_id != author_id {
            return Err("æ— æƒé™ç¼–è¾‘æ­¤æ–‡ç« ".into());
        }
    } else {
        return Err("æ–‡ç« ä¸å­˜åœ¨".into());
    }

    // æ„å»ºæ›´æ–°æŸ¥è¯¢
    let mut set_clauses = vec!["updated_at = $1".to_string()];
    let mut params: Vec<&(dyn tokio_postgres::types::ToSql + Sync)> = vec![&now];
    let mut param_count = 1;

    if let Some(title) = &input.title {
        param_count += 1;
        set_clauses.push(format!("title = ${}", param_count));
        params.push(title);
        
        // å¦‚æœæ ‡é¢˜æ›´æ–°ï¼Œä¹Ÿæ›´æ–° slug
        param_count += 1;
        let new_slug = generate_slug(title);
        let unique_slug = ensure_unique_slug(pool, &new_slug).await?;
        set_clauses.push(format!("slug = ${}", param_count));
        params.push(&unique_slug);
    }

    if let Some(content) = &input.content {
        param_count += 1;
        set_clauses.push(format!("content = ${}", param_count));
        params.push(content);
    }

    if let Some(excerpt) = &input.excerpt {
        param_count += 1;
        set_clauses.push(format!("excerpt = ${}", param_count));
        params.push(excerpt);
    }

    if let Some(image_url) = &input.image_url {
        param_count += 1;
        set_clauses.push(format!("image_url = ${}", param_count));
        params.push(image_url);
    }

    if let Some(category_id) = input.category_id {
        param_count += 1;
        set_clauses.push(format!("category_id = ${}", param_count));
        params.push(&category_id);
    }

    if let Some(status) = input.status {
        param_count += 1;
        let status_str = String::from(status);
        set_clauses.push(format!("status = ${}", param_count));
        params.push(&status_str);
        
        // å¦‚æœçŠ¶æ€å˜ä¸ºå·²å‘å¸ƒï¼Œè®¾ç½®å‘å¸ƒæ—¶é—´
        if status == ArticleStatus::Published {
            param_count += 1;
            set_clauses.push(format!("published_at = ${}", param_count));
            params.push(&now);
        }
    }

    param_count += 1;
    params.push(&id);

    let query = format!(
        "UPDATE articles SET {} WHERE id = ${}",
        set_clauses.join(", "),
        param_count
    );

    client.execute(&query, &params).await?;

    // æ›´æ–°æ ‡ç­¾å…³è”
    if let Some(tag_ids) = input.tag_ids {
        // åˆ é™¤ç°æœ‰å…³è”
        client
            .execute("DELETE FROM article_tags WHERE article_id = $1", &[&id])
            .await?;

        // æ·»åŠ æ–°å…³è”
        for tag_id in tag_ids {
            client
                .execute(
                    "INSERT INTO article_tags (article_id, tag_id) VALUES ($1, $2)",
                    &[&id, &tag_id],
                )
                .await?;
        }
    }

    // è¿”å›æ›´æ–°åçš„æ–‡ç« 
    get_article_by_id(pool, id)
        .await?
        .ok_or_else(|| "æ–‡ç« æ›´æ–°åæœªæ‰¾åˆ°".into())
}

pub async fn delete_article(
    pool: &Pool,
    id: &str,
    author_id: i64,
) -> Result<bool, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    let row = client
        .query_opt(
            "SELECT author_id FROM articles WHERE id = $1",
            &[&id],
        )
        .await?;

    if let Some(row) = row {
        let article_author_id: i64 = row.get(0);
        if article_author_id != author_id {
            return Err("æ— æƒé™åˆ é™¤æ­¤æ–‡ç« ".into());
        }
    } else {
        return Ok(false);
    }

    let rows_affected = client
        .execute("DELETE FROM articles WHERE id = $1", &[&id])
        .await?;

    Ok(rows_affected > 0)
}

pub async fn publish_article(
    pool: &Pool,
    id: &str,
    author_id: i64,
) -> Result<Article, Box<dyn std::error::Error>> {
    let input = UpdateArticleInput {
        status: Some(ArticleStatus::Published),
        ..Default::default()
    };
    
    update_article(pool, id, input, author_id).await
}

pub async fn increment_view_count(
    pool: &Pool,
    id: &str,
) -> Result<(), Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    
    client
        .execute(
            "UPDATE articles SET view_count = view_count + 1 WHERE id = $1",
            &[&id],
        )
        .await?;

    Ok(())
}

// å·¥å…·å‡½æ•°
fn generate_slug(title: &str) -> String {
    title
        .trim()
        .to_lowercase()
        .chars()
        .map(|c| match c {
            'a'..='z' | '0'..='9' => c,
            ' ' | '-' | '_' => '-',
            _ => '-',
        })
        .collect::<String>()
        .split('-')
        .filter(|s| !s.is_empty())
        .collect::<Vec<_>>()
        .join("-")
}

async fn ensure_unique_slug(
    pool: &Pool,
    base_slug: &str,
) -> Result<String, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let mut slug = base_slug.to_string();
    let mut counter = 1;

    loop {
        let row = client
            .query_opt(
                "SELECT COUNT(*) FROM articles WHERE slug = $1",
                &[&slug],
            )
            .await?;

        if let Some(row) = row {
            let count: i64 = row.get(0);
            if count == 0 {
                break;
            }
        }

        slug = format!("{}-{}", base_slug, counter);
        counter += 1;
    }

    Ok(slug)
}

impl Default for UpdateArticleInput {
    fn default() -> Self {
        Self {
            title: None,
            content: None,
            excerpt: None,
            image_url: None,
            category_id: None,
            tag_ids: None,
            status: None,
        }
    }
}
```
 ä»£ç 
```rust
// ## src/services/category_service.rs
use crate::database::*;
use chrono::Utc;
use deadpool_postgres::Pool;

pub async fn get_all_categories(
    pool: &Pool,
) -> Result<Vec<Category>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT id, name, slug, description, created_at 
             FROM categories 
             ORDER BY name ASC",
            &[],
        )
        .await?;

    let mut categories = Vec::new();
    for row in rows {
        categories.push(Category {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            description: row.get(3),
            created_at: row.get(4),
        });
    }

    Ok(categories)
}

pub async fn get_category_by_id(
    pool: &Pool,
    id: i64,
) -> Result<Option<Category>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let row = client
        .query_opt(
            "SELECT id, name, slug, description, created_at 
             FROM categories 
             WHERE id = $1",
            &[&id],
        )
        .await?;

    if let Some(row) = row {
        Ok(Some(Category {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            description: row.get(3),
            created_at: row.get(4),
        }))
    } else {
        Ok(None)
    }
}

pub async fn get_category_by_slug(
    pool: &Pool,
    slug: &str,
) -> Result<Option<Category>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let row = client
        .query_opt(
            "SELECT id, name, slug, description, created_at 
             FROM categories 
             WHERE slug = $1",
            &[&slug],
        )
        .await?;

    if let Some(row) = row {
        Ok(Some(Category {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            description: row.get(3),
            created_at: row.get(4),
        }))
    } else {
        Ok(None)
    }
}

pub async fn create_category(
    pool: &Pool,
    input: CreateCategoryInput,
) -> Result<Category, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let now = Utc::now();

    // æ£€æŸ¥ slug æ˜¯å¦å”¯ä¸€
    let unique_slug = ensure_unique_slug(pool, &input.slug).await?;

    // æ’å…¥åˆ†ç±»
    let row = client
        .query_one(
            "INSERT INTO categories (name, slug, description, created_at)
             VALUES ($1, $2, $3, $4)
             RETURNING id, name, slug, description, created_at",
            &[&input.name, &unique_slug, &input.description, &now],
        )
        .await?;

    Ok(Category {
        id: row.get(0),
        name: row.get(1),
        slug: row.get(2),
        description: row.get(3),
        created_at: row.get(4),
    })
}

pub async fn update_category(
    pool: &Pool,
    id: i64,
    input: CreateCategoryInput,
) -> Result<Option<Category>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // æ£€æŸ¥åˆ†ç±»æ˜¯å¦å­˜åœ¨
    let exists = client
        .query_opt("SELECT id FROM categories WHERE id = $1", &[&id])
        .await?;

    if exists.is_none() {
        return Ok(None);
    }

    // å¦‚æœ slug æœ‰å˜åŒ–ï¼Œæ£€æŸ¥å”¯ä¸€æ€§
    let unique_slug = if input.slug != get_category_slug_by_id(pool, id).await? {
        ensure_unique_slug(pool, &input.slug).await?
    } else {
        input.slug
    };

    let row = client
        .query_one(
            "UPDATE categories 
             SET name = $1, slug = $2, description = $3
             WHERE id = $4
             RETURNING id, name, slug, description, created_at",
            &[&input.name, &unique_slug, &input.description, &id],
        )
        .await?;

    Ok(Some(Category {
        id: row.get(0),
        name: row.get(1),
        slug: row.get(2),
        description: row.get(3),
        created_at: row.get(4),
    }))
}

pub async fn delete_category(
    pool: &Pool,
    id: i64,
) -> Result<bool, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ç« ä½¿ç”¨æ­¤åˆ†ç±»
    let article_count_row = client
        .query_opt(
            "SELECT COUNT(*) FROM articles WHERE category_id = $1",
            &[&id],
        )
        .await?;

    if let Some(row) = article_count_row {
        let count: i64 = row.get(0);
        if count > 0 {
            return Err("æ— æ³•åˆ é™¤åŒ…å«æ–‡ç« çš„åˆ†ç±»".into());
        }
    }

    let rows_affected = client
        .execute("DELETE FROM categories WHERE id = $1", &[&id])
        .await?;

    Ok(rows_affected > 0)
}

pub async fn get_categories_with_article_count(
    pool: &Pool,
) -> Result<Vec<(Category, i32)>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT c.id, c.name, c.slug, c.description, c.created_at,
                    COUNT(a.id) as article_count
             FROM categories c
             LEFT JOIN articles a ON c.id = a.category_id AND a.status = 'published'
             GROUP BY c.id, c.name, c.slug, c.description, c.created_at
             ORDER BY c.name ASC",
            &[],
        )
        .await?;

    let mut result = Vec::new();
    for row in rows {
        let category = Category {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            description: row.get(3),
            created_at: row.get(4),
        };
        let article_count: i64 = row.get(5);
        result.push((category, article_count as i32));
    }

    Ok(result)
}

// å·¥å…·å‡½æ•°
async fn ensure_unique_slug(
    pool: &Pool,
    base_slug: &str,
) -> Result<String, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let mut slug = base_slug.to_string();
    let mut counter = 1;

    loop {
        let row = client
            .query_opt(
                "SELECT COUNT(*) FROM categories WHERE slug = $1",
                &[&slug],
            )
            .await?;

        if let Some(row) = row {
            let count: i64 = row.get(0);
            if count == 0 {
                break;
            }
        }

        slug = format!("{}-{}", base_slug, counter);
        counter += 1;
    }

    Ok(slug)
}

async fn get_category_slug_by_id(
    pool: &Pool,
    id: i64,
) -> Result<String, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    
    let row = client
        .query_one("SELECT slug FROM categories WHERE id = $1", &[&id])
        .await?;
    
    Ok(row.get(0))
}
```
 ä»£ç 
```rust
// ## src/services/tag_service.rs
use crate::database::*;
use chrono::Utc;
use deadpool_postgres::Pool;

pub async fn get_all_tags(
    pool: &Pool,
) -> Result<Vec<Tag>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT id, name, slug, created_at 
             FROM tags 
             ORDER BY name ASC",
            &[],
        )
        .await?;

    let mut tags = Vec::new();
    for row in rows {
        tags.push(Tag {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            created_at: row.get(3),
        });
    }

    Ok(tags)
}

pub async fn get_tag_by_id(
    pool: &Pool,
    id: i64,
) -> Result<Option<Tag>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let row = client
        .query_opt(
            "SELECT id, name, slug, created_at 
             FROM tags 
             WHERE id = $1",
            &[&id],
        )
        .await?;

    if let Some(row) = row {
        Ok(Some(Tag {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            created_at: row.get(3),
        }))
    } else {
        Ok(None)
    }
}

pub async fn get_tag_by_slug(
    pool: &Pool,
    slug: &str,
) -> Result<Option<Tag>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let row = client
        .query_opt(
            "SELECT id, name, slug, created_at 
             FROM tags 
             WHERE slug = $1",
            &[&slug],
        )
        .await?;

    if let Some(row) = row {
        Ok(Some(Tag {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            created_at: row.get(3),
        }))
    } else {
        Ok(None)
    }
}

pub async fn create_tag(
    pool: &Pool,
    input: CreateTagInput,
) -> Result<Tag, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let now = Utc::now();

    // æ£€æŸ¥ slug æ˜¯å¦å”¯ä¸€
    let unique_slug = ensure_unique_slug(pool, &input.slug).await?;

    // æ’å…¥æ ‡ç­¾
    let row = client
        .query_one(
            "INSERT INTO tags (name, slug, created_at)
             VALUES ($1, $2, $3)
             RETURNING id, name, slug, created_at",
            &[&input.name, &unique_slug, &now],
        )
        .await?;

    Ok(Tag {
        id: row.get(0),
        name: row.get(1),
        slug: row.get(2),
        created_at: row.get(3),
    })
}

pub async fn update_tag(
    pool: &Pool,
    id: i64,
    input: CreateTagInput,
) -> Result<Option<Tag>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // æ£€æŸ¥æ ‡ç­¾æ˜¯å¦å­˜åœ¨
    let exists = client
        .query_opt("SELECT id FROM tags WHERE id = $1", &[&id])
        .await?;

    if exists.is_none() {
        return Ok(None);
    }

    // å¦‚æœ slug æœ‰å˜åŒ–ï¼Œæ£€æŸ¥å”¯ä¸€æ€§
    let unique_slug = if input.slug != get_tag_slug_by_id(pool, id).await? {
        ensure_unique_slug(pool, &input.slug).await?
    } else {
        input.slug
    };

    let row = client
        .query_one(
            "UPDATE tags 
             SET name = $1, slug = $2
             WHERE id = $3
             RETURNING id, name, slug, created_at",
            &[&input.name, &unique_slug, &id],
        )
        .await?;

    Ok(Some(Tag {
        id: row.get(0),
        name: row.get(1),
        slug: row.get(2),
        created_at: row.get(3),
    }))
}

pub async fn delete_tag(
    pool: &Pool,
    id: i64,
) -> Result<bool, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // å…ˆåˆ é™¤æ–‡ç« -æ ‡ç­¾å…³è”
    client
        .execute("DELETE FROM article_tags WHERE tag_id = $1", &[&id])
        .await?;

    // åˆ é™¤æ ‡ç­¾
    let rows_affected = client
        .execute("DELETE FROM tags WHERE id = $1", &[&id])
        .await?;

    Ok(rows_affected > 0)
}

pub async fn get_tags_with_article_count(
    pool: &Pool,
) -> Result<Vec<(Tag, i32)>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT t.id, t.name, t.slug, t.created_at,
                    COUNT(at.article_id) as article_count
             FROM tags t
             LEFT JOIN article_tags at ON t.id = at.tag_id
             LEFT JOIN articles a ON at.article_id = a.id AND a.status = 'published'
             GROUP BY t.id, t.name, t.slug, t.created_at
             ORDER BY t.name ASC",
            &[],
        )
        .await?;

    let mut result = Vec::new();
    for row in rows {
        let tag = Tag {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            created_at: row.get(3),
        };
        let article_count: i64 = row.get(4);
        result.push((tag, article_count as i32));
    }

    Ok(result)
}

pub async fn get_tags_for_article(
    pool: &Pool,
    article_id: &str,
) -> Result<Vec<Tag>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT t.id, t.name, t.slug, t.created_at
             FROM tags t
             INNER JOIN article_tags at ON t.id = at.tag_id
             WHERE at.article_id = $1
             ORDER BY t.name ASC",
            &[&article_id],
        )
        .await?;

    let mut tags = Vec::new();
    for row in rows {
        tags.push(Tag {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            created_at: row.get(3),
        });
    }

    Ok(tags)
}

pub async fn get_popular_tags(
    pool: &Pool,
    limit: i32,
) -> Result<Vec<(Tag, i32)>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT t.id, t.name, t.slug, t.created_at,
                    COUNT(at.article_id) as article_count
             FROM tags t
             INNER JOIN article_tags at ON t.id = at.tag_id
             INNER JOIN articles a ON at.article_id = a.id AND a.status = 'published'
             GROUP BY t.id, t.name, t.slug, t.created_at
             HAVING COUNT(at.article_id) > 0
             ORDER BY article_count DESC, t.name ASC
             LIMIT $1",
            &[&limit],
        )
        .await?;

    let mut result = Vec::new();
    for row in rows {
        let tag = Tag {
            id: row.get(0),
            name: row.get(1),
            slug: row.get(2),
            created_at: row.get(3),
        };
        let article_count: i64 = row.get(4);
        result.push((tag, article_count as i32));
    }

    Ok(result)
}

// å·¥å…·å‡½æ•°
async fn ensure_unique_slug(
    pool: &Pool,
    base_slug: &str,
) -> Result<String, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    let mut slug = base_slug.to_string();
    let mut counter = 1;

    loop {
        let row = client
            .query_opt(
                "SELECT COUNT(*) FROM tags WHERE slug = $1",
                &[&slug],
            )
            .await?;

        if let Some(row) = row {
            let count: i64 = row.get(0);
            if count == 0 {
                break;
            }
        }

        slug = format!("{}-{}", base_slug, counter);
        counter += 1;
    }

    Ok(slug)
}

async fn get_tag_slug_by_id(
    pool: &Pool,
    id: i64,
) -> Result<String, Box<dyn std::error::Error>> {
    let client = pool.get().await?;
    
    let row = client
        .query_one("SELECT slug FROM tags WHERE id = $1", &[&id])
        .await?;
    
    Ok(row.get(0))
}
```
 ä»£ç 
```rust
// ## src/handlers/articles.rs
use crate::database::*;
use crate::handlers::DbPool;
use crate::services::{article_service, category_service, tag_service};
use axum::{
    extract::{Path, Query, State},
    http::StatusCode,
    Json,
};
use serde::Deserialize;
use std::collections::HashMap;

#[derive(Deserialize)]
pub struct ArticleQueryParams {
    pub page: Option<i32>,
    pub per_page: Option<i32>,
    pub status: Option<String>,
    pub category: Option<String>,
    pub tag: Option<String>,
    pub author_id: Option<i64>,
    pub search: Option<String>,
}

// è·å–æ–‡ç« åˆ—è¡¨
pub async fn get_articles(
    State(pool): State<DbPool>,
    Query(params): Query<ArticleQueryParams>,
) -> Result<Json<ArticleConnection>, (StatusCode, &'static str)> {
    println!("ğŸ“° è·å–æ–‡ç« åˆ—è¡¨");

    let page = params.page.unwrap_or(1).max(1);
    let per_page = params.per_page.unwrap_or(10).max(1).min(100);

    // æ„å»ºè¿‡æ»¤å™¨
    let mut filter = ArticleFilter {
        status: None,
        category_id: None,
        tag_ids: None,
        author_id: params.author_id,
        search: params.search,
    };

    // çŠ¶æ€è¿‡æ»¤
    if let Some(status_str) = params.status {
        match status_str.as_str() {
            "published" => filter.status = Some(ArticleStatus::Published),
            "draft" => filter.status = Some(ArticleStatus::Draft),
            "archived" => filter.status = Some(ArticleStatus::Archived),
            _ => {}
        }
    }

    // åˆ†ç±»è¿‡æ»¤
    if let Some(category_slug) = params.category {
        if let Ok(Some(category)) = category_service::get_category_by_slug(&pool, &category_slug).await {
            filter.category_id = Some(category.id);
        }
    }

    // æ ‡ç­¾è¿‡æ»¤
    if let Some(tag_slug) = params.tag {
        if let Ok(Some(tag)) = tag_service::get_tag_by_slug(&pool, &tag_slug).await {
            filter.tag_ids = Some(vec![tag.id]);
        }
    }

    match article_service::get_articles_paginated(&pool, &filter, page, per_page).await {
        Ok(result) => {
            println!("âœ… è¿”å› {} ç¯‡æ–‡ç« ï¼Œå…± {} é¡µ", result.articles.len(), result.total_pages);
            Ok(Json(result))
        }
        Err(e) => {
            eprintln!("âŒ è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "è·å–æ–‡ç« åˆ—è¡¨å¤±è´¥"))
        }
    }
}

// æ ¹æ®IDè·å–æ–‡ç« 
pub async fn get_article_by_id(
    State(pool): State<DbPool>,
    Path(id): Path<String>,
) -> Result<Json<ArticleResponse>, (StatusCode, &'static str)> {
    println!("ğŸ“° è·å–æ–‡ç« : {}", id);

    match article_service::get_article_by_id(&pool, &id).await {
        Ok(Some(article)) => {
            // å¢åŠ æµè§ˆæ¬¡æ•°
            if let Err(e) = article_service::increment_view_count(&pool, &id).await {
                eprintln!("âš ï¸ æ›´æ–°æµè§ˆæ¬¡æ•°å¤±è´¥: {:?}", e);
            }
            
            println!("âœ… æ–‡ç« æ‰¾åˆ°: {}", article.title);
            Ok(Json(ArticleResponse { article }))
        }
        Ok(None) => {
            println!("âŒ æ–‡ç« ä¸å­˜åœ¨: {}", id);
            Err((StatusCode::NOT_FOUND, "æ–‡ç« ä¸å­˜åœ¨"))
        }
        Err(e) => {
            eprintln!("âŒ è·å–æ–‡ç« å¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "è·å–æ–‡ç« å¤±è´¥"))
        }
    }
}

// æ ¹æ®slugè·å–æ–‡ç« 
pub async fn get_article_by_slug(
    State(pool): State<DbPool>,
    Path(slug): Path<String>,
) -> Result<Json<ArticleResponse>, (StatusCode, &'static str)> {
    println!("ğŸ“° æ ¹æ®slugè·å–æ–‡ç« : {}", slug);

    match article_service::get_article_by_slug(&pool, &slug).await {
        Ok(Some(article)) => {
            // å¢åŠ æµè§ˆæ¬¡æ•°
            if let Err(e) = article_service::increment_view_count(&pool, &article.id).await {
                eprintln!("âš ï¸ æ›´æ–°æµè§ˆæ¬¡æ•°å¤±è´¥: {:?}", e);
            }
            
            println!("âœ… æ–‡ç« æ‰¾åˆ°: {}", article.title);
            Ok(Json(ArticleResponse { article }))
        }
        Ok(None) => {
            println!("âŒ æ–‡ç« ä¸å­˜åœ¨: {}", slug);
            Err((StatusCode::NOT_FOUND, "æ–‡ç« ä¸å­˜åœ¨"))
        }
        Err(e) => {
            eprintln!("âŒ è·å–æ–‡ç« å¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "è·å–æ–‡ç« å¤±è´¥"))
        }
    }
}

// åˆ›å»ºæ–‡ç« 
pub async fn create_article(
    State(pool): State<DbPool>,
    Json(input): Json<CreateArticleInput>,
) -> Result<Json<ArticleResponse>, (StatusCode, &'static str)> {
    println!("ğŸ“ åˆ›å»ºæ–°æ–‡ç« : {}", input.title);

    // è¿™é‡Œåº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–ç”¨æˆ·ä¿¡æ¯
    // æš‚æ—¶ç¡¬ç¼–ç ä¸€ä¸ªç”¨æˆ·IDï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®ç°è®¤è¯ä¸­é—´ä»¶
    let author_id = 1i64; // TODO: ä»è®¤è¯ä¿¡æ¯è·å–

    // éªŒè¯è¾“å…¥
    if input.title.trim().is_empty() {
        return Err((StatusCode::BAD_REQUEST, "æ–‡ç« æ ‡é¢˜ä¸èƒ½ä¸ºç©º"));
    }
    if input.content.trim().is_empty() {
        return Err((StatusCode::BAD_REQUEST, "æ–‡ç« å†…å®¹ä¸èƒ½ä¸ºç©º"));
    }

    match article_service::create_article(&pool, input, author_id).await {
        Ok(article) => {
            println!("âœ… æ–‡ç« åˆ›å»ºæˆåŠŸ: {} ({})", article.title, article.id);
            Ok(Json(ArticleResponse { article }))
        }
        Err(e) => {
            eprintln!("âŒ åˆ›å»ºæ–‡ç« å¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "åˆ›å»ºæ–‡ç« å¤±è´¥"))
        }
    }
}

// æ›´æ–°æ–‡ç« 
pub async fn update_article(
    State(pool): State<DbPool>,
    Path(id): Path<String>,
    Json(input): Json<UpdateArticleInput>,
) -> Result<Json<ArticleResponse>, (StatusCode, &'static str)> {
    println!("ğŸ“ æ›´æ–°æ–‡ç« : {}", id);

    // è¿™é‡Œåº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–ç”¨æˆ·ä¿¡æ¯
    let author_id = 1i64; // TODO: ä»è®¤è¯ä¿¡æ¯è·å–

    match article_service::update_article(&pool, &id, input, author_id).await {
        Ok(article) => {
            println!("âœ… æ–‡ç« æ›´æ–°æˆåŠŸ: {}", article.title);
            Ok(Json(ArticleResponse { article }))
        }
        Err(e) => {
            eprintln!("âŒ æ›´æ–°æ–‡ç« å¤±è´¥: {:?}", e);
            if e.to_string().contains("æ— æƒé™") {
                Err((StatusCode::FORBIDDEN, "æ— æƒé™ç¼–è¾‘æ­¤æ–‡ç« "))
            } else if e.to_string().contains("ä¸å­˜åœ¨") {
                Err((StatusCode::NOT_FOUND, "æ–‡ç« ä¸å­˜åœ¨"))
            } else {
                Err((StatusCode::INTERNAL_SERVER_ERROR, "æ›´æ–°æ–‡ç« å¤±è´¥"))
            }
        }
    }
}

// åˆ é™¤æ–‡ç« 
pub async fn delete_article(
    State(pool): State<DbPool>,
    Path(id): Path<String>,
) -> Result<Json<serde_json::Value>, (StatusCode, &'static str)> {
    println!("ğŸ—‘ï¸ åˆ é™¤æ–‡ç« : {}", id);

    // è¿™é‡Œåº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–ç”¨æˆ·ä¿¡æ¯
    let author_id = 1i64; // TODO: ä»è®¤è¯ä¿¡æ¯è·å–

    match article_service::delete_article(&pool, &id, author_id).await {
        Ok(true) => {
            println!("âœ… æ–‡ç« åˆ é™¤æˆåŠŸ: {}", id);
            Ok(Json(serde_json::json!({"message": "æ–‡ç« åˆ é™¤æˆåŠŸ"})))
        }
        Ok(false) => {
            println!("âŒ æ–‡ç« ä¸å­˜åœ¨: {}", id);
            Err((StatusCode::NOT_FOUND, "æ–‡ç« ä¸å­˜åœ¨"))
        }
        Err(e) => {
            eprintln!("âŒ åˆ é™¤æ–‡ç« å¤±è´¥: {:?}", e);
            if e.to_string().contains("æ— æƒé™") {
                Err((StatusCode::FORBIDDEN, "æ— æƒé™åˆ é™¤æ­¤æ–‡ç« "))
            } else {
                Err((StatusCode::INTERNAL_SERVER_ERROR, "åˆ é™¤æ–‡ç« å¤±è´¥"))
            }
        }
    }
}

// å‘å¸ƒæ–‡ç« 
pub async fn publish_article(
    State(pool): State<DbPool>,
    Path(id): Path<String>,
) -> Result<Json<ArticleResponse>, (StatusCode, &'static str)> {
    println!("ğŸ“¢ å‘å¸ƒæ–‡ç« : {}", id);

    // è¿™é‡Œåº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–ç”¨æˆ·ä¿¡æ¯
    let author_id = 1i64; // TODO: ä»è®¤è¯ä¿¡æ¯è·å–

    match article_service::publish_article(&pool, &id, author_id).await {
        Ok(article) => {
            println!("âœ… æ–‡ç« å‘å¸ƒæˆåŠŸ: {}", article.title);
            Ok(Json(ArticleResponse { article }))
        }
        Err(e) => {
            eprintln!("âŒ å‘å¸ƒæ–‡ç« å¤±è´¥: {:?}", e);
            if e.to_string().contains("æ— æƒé™") {
                Err((StatusCode::FORBIDDEN, "æ— æƒé™å‘å¸ƒæ­¤æ–‡ç« "))
            } else if e.to_string().contains("ä¸å­˜åœ¨") {
                Err((StatusCode::NOT_FOUND, "æ–‡ç« ä¸å­˜åœ¨"))
            } else {
                Err((StatusCode::INTERNAL_SERVER_ERROR, "å‘å¸ƒæ–‡ç« å¤±è´¥"))
            }
        }
    }
}

// è·å–åˆ†ç±»åˆ—è¡¨
pub async fn get_categories(
    State(pool): State<DbPool>,
) -> Result<Json<CategoriesResponse>, (StatusCode, &'static str)> {
    println!("ğŸ“‚ è·å–åˆ†ç±»åˆ—è¡¨");

    match category_service::get_all_categories(&pool).await {
        Ok(categories) => {
            println!("âœ… è¿”å› {} ä¸ªåˆ†ç±»", categories.len());
            Ok(Json(CategoriesResponse { categories }))
        }
        Err(e) => {
            eprintln!("âŒ è·å–åˆ†ç±»åˆ—è¡¨å¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "è·å–åˆ†ç±»åˆ—è¡¨å¤±è´¥"))
        }
    }
}

// è·å–æ ‡ç­¾åˆ—è¡¨
pub async fn get_tags(
    State(pool): State<DbPool>,
) -> Result<Json<TagsResponse>, (StatusCode, &'static str)> {
    println!("ğŸ·ï¸ è·å–æ ‡ç­¾åˆ—è¡¨");

    match tag_service::get_all_tags(&pool).await {
        Ok(tags) => {
            println!("âœ… è¿”å› {} ä¸ªæ ‡ç­¾", tags.len());
            Ok(Json(TagsResponse { tags }))
        }
        Err(e) => {
            eprintln!("âŒ è·å–æ ‡ç­¾åˆ—è¡¨å¤±è´¥: {:?}", e);
            Err((StatusCode::INTERNAL_SERVER_ERROR, "è·å–æ ‡ç­¾åˆ—è¡¨å¤±è´¥"))
        }
    }
}
```
 ä»£ç 
```rust
// ## src/handlers/graphql.rs
use crate::graphql::{BlogSchema, GraphQLContext};
use crate::handlers::DbPool;
use async_graphql::http::{playground_source, GraphQLPlaygroundConfig};
use async_graphql_axum::{GraphQLRequest, GraphQLResponse};
use axum::{
    extract::State,
    response::{Html, IntoResponse},
    Extension,
};

// GraphQL æŸ¥è¯¢å¤„ç†å™¨
pub async fn graphql_handler(
    State(pool): State<DbPool>,
    schema: Extension<BlogSchema>,
    req: GraphQLRequest,
) -> GraphQLResponse {
    println!("ğŸ” å¤„ç† GraphQL è¯·æ±‚");
    
    // è¿™é‡Œåº”è¯¥ä»è®¤è¯ä¸­é—´ä»¶è·å–ç”¨æˆ·ä¿¡æ¯
    // æš‚æ—¶ä½¿ç”¨ Noneï¼Œå®é™…åº”ç”¨ä¸­éœ€è¦å®ç°è®¤è¯ä¸­é—´ä»¶
    let current_user = None;
    
    let context = GraphQLContext::new(pool, current_user);
    
    schema.execute(req.into_inner().data(context)).await.into()
}

// GraphQL Playground å¤„ç†å™¨
pub async fn graphql_playground() -> impl IntoResponse {
    Html(playground_source(GraphQLPlaygroundConfig::new("/graphql")))
}
```
 ä»£ç 
```rust
// ## src/main.rs
mod config;
mod database;
mod handlers;
mod services;
mod utils;
mod graphql;

use axum::{
    routing::{get, post, put, delete},
    Router,
    Extension,
};
use std::net::SocketAddr;
use tokio::net::TcpListener;

use config::AppConfig;
use database::init::init_database;
use handlers::{auth, comments, health, articles, graphql as gql_handler};
use utils::cors::create_cors_layer;
use graphql::create_schema;

#[tokio::main]
async fn main() {
    println!("ğŸš€ å¯åŠ¨åº”ç”¨ç¨‹åº...");

    // åˆå§‹åŒ–é…ç½®
    let config = AppConfig::from_env();

    // åˆ›å»ºæ•°æ®åº“è¿æ¥æ± 
    let pool = config.create_db_pool().expect("æ— æ³•åˆ›å»ºæ•°æ®åº“è¿æ¥æ± ");

    // åˆå§‹åŒ–æ•°æ®åº“
    if let Err(e) = init_database(&pool).await {
        eprintln!("âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {:?}", e);
        std::process::exit(1);
    }
    println!("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ");

    // åˆ›å»º GraphQL Schema
    let schema = create_schema(pool.clone());
    println!("âœ… GraphQL Schema åˆ›å»ºå®Œæˆ");

    // åˆ›å»ºè·¯ç”±
    let app = Router::new()
        // å¥åº·æ£€æŸ¥
        .route("/", get(health::health_check))
        .route("/api/health", get(health::health_check))
        
        // è®¤è¯ç›¸å…³
        .route("/api/google-login", post(auth::handle_google_login))
        .route("/api/google-logout", post(auth::handle_google_logout))
        
        // è¯„è®ºç›¸å…³
        .route("/api/comments", get(comments::get_comments))
        .route("/api/comments", post(comments::create_comment))
        .route("/api/comments/vote", post(comments::handle_vote))
        
        // æ–‡ç« ç›¸å…³ REST API
        .route("/api/articles", get(articles::get_articles))
        .route("/api/articles", post(articles::create_article))
        .route("/api/articles/:id", get(articles::get_article_by_id))
        .route("/api/articles/:id", put(articles::update_article))
        .route("/api/articles/:id", delete(articles::delete_article))
        .route("/api/articles/:id/publish", post(articles::publish_article))
        .route("/api/articles/slug/:slug", get(articles::get_article_by_slug))
        
        // åˆ†ç±»å’Œæ ‡ç­¾
        .route("/api/categories", get(articles::get_categories))
        .route("/api/tags", get(articles::get_tags))
        
        // GraphQL
        .route("/graphql", post(gql_handler::graphql_handler))
        .route("/graphql", get(gql_handler::graphql_handler))
        .route("/playground", get(gql_handler::graphql_playground))
        
        // æ·»åŠ çŠ¶æ€å’Œæ‰©å±•
        .with_state(pool)
        .layer(Extension(schema))
        .layer(create_cors_layer());

    let addr = SocketAddr::from(([0, 0, 0, 0], config.port));

    println!("ğŸš€ æœåŠ¡è¿è¡Œåœ¨ http://0.0.0.0:{}", config.port);
    println!("ğŸ”— æœ¬åœ°è®¿é—®: http://localhost:{}", config.port);
    println!("ğŸ—„ï¸ ä½¿ç”¨ PostgreSQL æ•°æ®åº“: {}", config.db_name);
    println!();
    println!("ğŸ“° æ–‡ç« ç®¡ç†åŠŸèƒ½å·²å¯ç”¨:");
    println!("   â€¢ REST API: /api/articles");
    println!("   â€¢ GraphQL API: /graphql");
    println!("   â€¢ GraphQL Playground: /playground");
    println!();
    println!("ğŸ’¬ è®¨è®ºåŒºåŠŸèƒ½å·²å¯ç”¨:");
    println!("   â€¢ è¯„è®ºç³»ç»Ÿ: /api/comments");
    println!("   â€¢ æŠ•ç¥¨åŠŸèƒ½: /api/comments/vote");
    println!("   â€¢ å›å¤åŠŸèƒ½å·²å¯ç”¨");
    println!();
    println!("ğŸ·ï¸ å†…å®¹ç®¡ç†:");
    println!("   â€¢ åˆ†ç±»ç®¡ç†: /api/categories");
    println!("   â€¢ æ ‡ç­¾ç®¡ç†: /api/tags");
    println!("   â€¢ Markdown æ”¯æŒ");
    println!("   â€¢ æ–‡ç« çŠ¶æ€ç®¡ç† (è‰ç¨¿/å‘å¸ƒ/å½’æ¡£)");

    let listener = TcpListener::bind(addr).await.unwrap();
    axum::serve(listener, app).await.unwrap();
}
```

### ç”¨æˆ·:
Continue
### ç³»ç»Ÿ:
æˆ‘æ¥ç»§ç»­å®Œå–„è¿™ä¸ªé¡¹ç›®ï¼Œæ·»åŠ ä¸€äº›é‡è¦çš„åŠŸèƒ½å’Œé…ç½®æ–‡ä»¶ã€‚ ä»£ç 
```rust
// ## src/services/comment_service.rs
use crate::database::{Comment, CommentAuthor, CreateCommentPayload};
use crate::services::vote_service;
use chrono::Utc;
use deadpool_postgres::Pool;
use uuid::Uuid;

pub fn validate_comment_payload(payload: &CreateCommentPayload) -> Result<(), &'static str> {
    let content = payload.content.trim();
    if content.is_empty() {
        return Err("è¯„è®ºå†…å®¹ä¸èƒ½ä¸ºç©º");
    }
    if content.len() > 500 {
        return Err("è¯„è®ºå†…å®¹ä¸èƒ½è¶…è¿‡500å­—ç¬¦");
    }
    if payload.author.name.trim().is_empty() || payload.author.email.trim().is_empty() {
        return Err("ç”¨æˆ·ä¿¡æ¯ä¸å®Œæ•´");
    }
    Ok(())
}

pub async fn get_all_comments(
    pool: &Pool,
    user_email: Option<&str>,
) -> Result<Vec<Comment>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT id, content, author_name, author_email, author_picture, created_at, parent_id, article_id
         FROM comments ORDER BY created_at ASC",
            &[],
        )
        .await?;

    let mut comments = Vec::new();

    for row in rows {
        let created_at = row.get(5);
        let mut comment = Comment {
            id: row.get(0),
            content: row.get(1),
            author: CommentAuthor {
                name: row.get(2),
                email: row.get(3),
                picture: row.get(4),
            },
            created_at,
            timestamp: created_at.to_rfc3339(),
            parent_id: row.get(6),
            article_id: row.get(7),
            upvotes: 0,
            downvotes: 0,
            user_vote: None,
            replies: Vec::new(),
        };

        // è·å–æŠ•ç¥¨ä¿¡æ¯
        if let Ok((upvotes, downvotes, user_vote)) =
            vote_service::get_comment_votes(pool, &comment.id, user_email).await
        {
            comment.upvotes = upvotes;
            comment.downvotes = downvotes;
            comment.user_vote = user_vote;
        }

        comments.push(comment);
    }

    Ok(comments)
}

pub async fn get_comments_for_article(
    pool: &Pool,
    article_id: &str,
    user_email: Option<&str>,
) -> Result<Vec<Comment>, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let rows = client
        .query(
            "SELECT id, content, author_name, author_email, author_picture, created_at, parent_id, article_id
         FROM comments 
         WHERE article_id = $1 
         ORDER BY created_at ASC",
            &[&article_id],
        )
        .await?;

    let mut comments = Vec::new();

    for row in rows {
        let created_at = row.get(5);
        let mut comment = Comment {
            id: row.get(0),
            content: row.get(1),
            author: CommentAuthor {
                name: row.get(2),
                email: row.get(3),
                picture: row.get(4),
            },
            created_at,
            timestamp: created_at.to_rfc3339(),
            parent_id: row.get(6),
            article_id: row.get(7),
            upvotes: 0,
            downvotes: 0,
            user_vote: None,
            replies: Vec::new(),
        };

        // è·å–æŠ•ç¥¨ä¿¡æ¯
        if let Ok((upvotes, downvotes, user_vote)) =
            vote_service::get_comment_votes(pool, &comment.id, user_email).await
        {
            comment.upvotes = upvotes;
            comment.downvotes = downvotes;
            comment.user_vote = user_vote;
        }

        comments.push(comment);
    }

    // æ„å»ºè¯„è®ºæ ‘ç»“æ„
    Ok(build_comment_tree(comments))
}

pub async fn create_new_comment(
    pool: &Pool,
    payload: CreateCommentPayload,
) -> Result<Comment, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // å¦‚æœæ˜¯å›å¤ï¼ŒéªŒè¯çˆ¶è¯„è®ºæ˜¯å¦å­˜åœ¨
    if let Some(parent_id) = &payload.parent_id {
        let row = client
            .query_opt("SELECT COUNT(*) FROM comments WHERE id = $1", &[parent_id])
            .await?;
        if let Some(row) = row {
            let count: i64 = row.get(0);
            if count == 0 {
                return Err("çˆ¶è¯„è®ºä¸å­˜åœ¨".into());
            }
        }
    }

    // å¦‚æœæŒ‡å®šäº†æ–‡ç« IDï¼ŒéªŒè¯æ–‡ç« æ˜¯å¦å­˜åœ¨
    if let Some(article_id) = &payload.article_id {
        let row = client
            .query_opt("SELECT COUNT(*) FROM articles WHERE id = $1", &[article_id])
            .await?;
        if let Some(row) = row {
            let count: i64 = row.get(0);
            if count == 0 {
                return Err("æ–‡ç« ä¸å­˜åœ¨".into());
            }
        }
    }

    let now = Utc::now();
    let comment_id = Uuid::new_v4().to_string();
    let content = payload.content.trim();

    // ä¿å­˜è¯„è®ºåˆ°æ•°æ®åº“
    client.execute(
        "INSERT INTO comments (id, content, author_name, author_email, author_picture, created_at, parent_id, article_id)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8)",
        &[
            &comment_id,
            &content,
            &payload.author.name,
            &payload.author.email,
            &payload.author.picture,
            &now,
            &payload.parent_id,
            &payload.article_id,
        ],
    ).await?;

    Ok(Comment {
        id: comment_id,
        content: content.to_string(),
        author: payload.author,
        created_at: now,
        timestamp: now.to_rfc3339(),
        parent_id: payload.parent_id,
        article_id: payload.article_id,
        upvotes: 0,
        downvotes: 0,
        user_vote: None,
        replies: Vec::new(),
    })
}

pub async fn delete_comment(
    pool: &Pool,
    comment_id: &str,
    user_email: &str,
) -> Result<bool, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    // æ£€æŸ¥è¯„è®ºæ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
    let row = client
        .query_opt(
            "SELECT author_email FROM comments WHERE id = $1",
            &[&comment_id],
        )
        .await?;

    if let Some(row) = row {
        let author_email: String = row.get(0);
        if author_email != user_email {
            return Err("æ— æƒé™åˆ é™¤æ­¤è¯„è®º".into());
        }
    } else {
        return Ok(false);
    }

    let rows_affected = client
        .execute("DELETE FROM comments WHERE id = $1", &[&comment_id])
        .await?;

    Ok(rows_affected > 0)
}

pub async fn get_comment_count_for_article(
    pool: &Pool,
    article_id: &str,
) -> Result<i32, Box<dyn std::error::Error>> {
    let client = pool.get().await?;

    let row = client
        .query_one(
            "SELECT COUNT(*) FROM comments WHERE article_id = $1",
            &[&article_id],
        )
        .await?;

    Ok(row.get::<_, i64>(0) as i32)
}

// æ„å»ºè¯„è®ºæ ‘ç»“æ„
fn build_comment_tree(comments: Vec<Comment>) -> Vec<Comment> {
    let mut comment_map = std::collections::HashMap::new();
    let mut root_comments = Vec::new();

    // å°†æ‰€æœ‰è¯„è®ºæ”¾å…¥ HashMap
    for comment in comments {
        comment_map.insert(comment.id.clone(), comment);
    }

    // æ„å»ºæ ‘ç»“æ„
    let comment_ids: Vec<String> = comment_map.keys().cloned().collect();
    
    for comment_id in comment_ids {
        if let Some(mut comment) = comment_map.remove(&comment_id) {
            if let Some(parent_id) = &comment.parent_id {
                // è¿™æ˜¯ä¸€ä¸ªå›å¤ï¼Œæ·»åŠ åˆ°çˆ¶è¯„è®ºçš„ replies ä¸­
                if let Some(parent_comment) = comment_map.get_mut(parent_id) {
                    parent_comment.replies.push(comment);
                }
            } else {
                // è¿™æ˜¯ä¸€ä¸ªé¡¶çº§è¯„è®º
                root_comments.push(comment);
            }
        }
    }

    // æ’åºå›å¤
    for comment in &mut root_comments {
        sort_replies(&mut comment.replies);
    }

    root_comments
}

fn sort_replies(replies: &mut Vec<Comment>) {
    replies.sort_by(|a, b| a.created_at.cmp(&b.created_at));
    for reply in replies {
        sort_replies(&mut reply.replies);
    }
}
```
 ä»£ç 
```rust
// ## src/middleware/auth.rs
use crate::database::User;
use axum::{
    extract::{Request, State},
    http::{HeaderMap, StatusCode},
    middleware::Next,
    response::Response,
};
use deadpool_postgres::Pool;

// å¯é€‰çš„è®¤è¯ä¸­é—´ä»¶ - å¦‚æœæœ‰è®¤è¯ä¿¡æ¯åˆ™éªŒè¯ï¼Œæ²¡æœ‰åˆ™è·³è¿‡
pub async fn optional_auth_middleware(
    State(pool): State<Pool>,
    headers: HeaderMap,
    mut request: Request,
    next: Next,
) -> Result<Response, StatusCode> {
    let user = extract_user_from_headers(&pool, &headers).await;
    
    // å°†ç”¨æˆ·ä¿¡æ¯æ·»åŠ åˆ°è¯·æ±‚æ‰©å±•ä¸­
    request.extensions_mut().insert(user);
    
    Ok(next.run(request).await)
}

// å¿…éœ€çš„è®¤è¯ä¸­é—´ä»¶ - å¿…é¡»æœ‰æœ‰æ•ˆçš„è®¤è¯ä¿¡æ¯
pub async fn required_auth_middleware(
    State(pool): State<Pool>,
    headers: HeaderMap,
    mut request: Request,
    next: Next,
) -> Result<Response, StatusCode> {
    let user = extract_user_from_headers(&pool, &headers).await;
    
    match user {
        Some(user) => {
            request.extensions_mut().insert(Some(user));
            Ok(next.run(request).await)
        }
        None => Err(StatusCode::UNAUTHORIZED),
    }
}

// ä»è¯·æ±‚å¤´ä¸­æå–ç”¨æˆ·ä¿¡æ¯
async fn extract_user_from_headers(
    pool: &Pool,
    headers: &HeaderMap,
) -> Option<User> {
    // å°è¯•ä» Authorization header è·å– token
    if let Some(auth_header) = headers.get("authorization") {
        if let Ok(auth_str) = auth_header.to_str() {
            if auth_str.starts_with("Bearer ") {
                let token = &auth_str[7..];
                return verify_token_and_get_user(pool, token).await;
            }
        }
    }
    
    // å°è¯•ä» Cookie è·å– session
    if let Some(cookie_header) = headers.get("cookie") {
        if let Ok(cookie_str) = cookie_header.to_str() {
            for cookie in cookie_str.split(';') {
                let cookie = cookie.trim();
                if cookie.starts_with("session=") {
                    let session_token = &cookie[8..];
                    return verify_session_and_get_user(pool, session_token).await;
                }
            }
        }
    }
    
    None
}

// éªŒè¯ JWT token å¹¶è·å–ç”¨æˆ·ä¿¡æ¯
async fn verify_token_and_get_user(
    pool: &Pool,
    token: &str,
) -> Option<User> {
    // è¿™é‡Œåº”è¯¥å®ç° JWT token éªŒè¯é€»è¾‘
    // 1. éªŒè¯ token ç­¾å
    // 2. æ£€æŸ¥ token æ˜¯å¦è¿‡æœŸ
    // 3. ä» token ä¸­æå–ç”¨æˆ· ID
    // 4. ä»æ•°æ®åº“è·å–ç”¨æˆ·ä¿¡æ¯
    
    // æš‚æ—¶çš„ç¤ºä¾‹å®ç° - ç”Ÿäº§ç¯å¢ƒéœ€è¦ä½¿ç”¨çœŸå®çš„ JWT åº“
    if token == "demo_token" {
        if let Ok(client) = pool.get().await {
            if let Ok(row) = client.query_one(
                "SELECT id, google_id, email, name, picture, created_at, last_login 
                 FROM users WHERE id = 1",
                &[],
            ).await {
                return Some(User {
                    id: row.get(0),
                    google_id: row.get(1),
                    email: row.get(2),
                    name: row.get(3),
                    picture: row.get(4),
                    created_at: row.get(5),
                    last_login: row.get(6),
                });
            }
        }
    }
    
    None
}

// éªŒè¯ session å¹¶è·å–ç”¨æˆ·ä¿¡æ¯
async fn verify_session_and_get_user(
    pool: &Pool,
    session_token: &str,
) -> Option<User> {
    // è¿™é‡Œåº”è¯¥å®ç° session éªŒè¯é€»è¾‘
    // 1. ä» Redis æˆ–æ•°æ®åº“ä¸­æŸ¥æ‰¾ session
    // 2. æ£€æŸ¥ session æ˜¯å¦æœ‰æ•ˆ
    // 3. è·å–ç”¨æˆ·ä¿¡æ¯
    
    // æš‚æ—¶çš„ç¤ºä¾‹å®ç°
    if session_token.len() > 10 {
        // ç®€å•çš„ session éªŒè¯é€»è¾‘
        return verify_token_and_get_user(pool, "demo_token").await;
    }
    
    None
}

// ä»è¯·æ±‚æ‰©å±•ä¸­è·å–å½“å‰ç”¨æˆ·
pub fn get_current_user_from_request(request: &Request) -> Option<User> {
    request.extensions().get::<Option<User>>()?.clone()
}
```
 ä»£ç 
```rust
// ## src/middleware/mod.rs
pub mod auth;

pub use auth::*;
```
 ä»£ç 
```rust
// ## src/utils/helpers.rs
use chrono::{DateTime, Utc};
use regex::Regex;

/// ç”Ÿæˆæ–‡ç« æ‘˜è¦
pub fn generate_excerpt(content: &str, max_length: usize) -> String {
    // ç§»é™¤ Markdown æ ‡è®°
    let cleaned_content = strip_markdown(content);
    
    // æˆªå–æŒ‡å®šé•¿åº¦
    if cleaned_content.len() <= max_length {
        cleaned_content
    } else {
        let truncated = &cleaned_content[..max_length];
        // æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å•è¯
        if let Some(last_space) = truncated.rfind(' ') {
            format!("{}...", &truncated[..last_space])
        } else {
            format!("{}...", truncated)
        }
    }
}

/// ç§»é™¤ Markdown æ ‡è®°
pub fn strip_markdown(content: &str) -> String {
    let mut result = content.to_string();
    
    // ç§»é™¤æ ‡é¢˜æ ‡è®°
    let header_re = Regex::new(r"^#{1,6}\s+").unwrap();
    result = header_re.replace_all(&result, "").to_string();
    
    // ç§»é™¤ç²—ä½“å’Œæ–œä½“
    let bold_italic_re = Regex::new(r"\*{1,2}([^*]+)\*{1,2}").unwrap();
    result = bold_italic_re.replace_all(&result, "$1").to_string();
    
    // ç§»é™¤ä»£ç å—
    let code_block_re = Regex::new(r"```[^`]*```").unwrap();
    result = code_block_re.replace_all(&result, "").to_string();
    
    // ç§»é™¤å†…è”ä»£ç 
    let inline_code_re = Regex::new(r"`([^`]+)`").unwrap();
    result = inline_code_re.replace_all(&result, "$1").to_string();
    
    // ç§»é™¤é“¾æ¥
    let link_re = Regex::new(r"\[([^\]]+)\]\([^\)]+\)").unwrap();
    result = link_re.replace_all(&result, "$1").to_string();
    
    // ç§»é™¤å›¾ç‰‡
    let image_re = Regex::new(r"!\[([^\]]*)\]\([^\)]+\)").unwrap();
    result = image_re.replace_all(&result, "$1").to_string();
    
    // ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
    let whitespace_re = Regex::new(r"\s+").unwrap();
    result = whitespace_re.replace_all(&result, " ").to_string();
    
    result.trim().to_string()
}

/// ç”Ÿæˆ URL å‹å¥½çš„ slug
pub fn slugify(text: &str) -> String {
    let mut slug = text
        .trim()
        .to_lowercase()
        .chars()
        .map(|c| match c {
            'a'..='z' | '0'..='9' => c,
            ' ' | '-' | '_' => '-',
            'Ã¡' | 'Ã ' | 'Ã¤' | 'Ã¢' => 'a',
            'Ã©' | 'Ã¨' | 'Ã«' | 'Ãª' => 'e',
            'Ã­' | 'Ã¬' | 'Ã¯' | 'Ã®' => 'i',
            'Ã³' | 'Ã²' | 'Ã¶' | 'Ã´' => 'o',
            'Ãº' | 'Ã¹' | 'Ã¼' | 'Ã»' => 'u',
            'Ã±' => 'n',
            'Ã§' => 'c',
            _ => '-',
        })
        .collect::<String>();
    
    // ç§»é™¤å¤šä½™çš„è¿å­—ç¬¦
    let multiple_dash_re = Regex::new(r"-+").unwrap();
    slug = multiple_dash_re.replace_all(&slug, "-").to_string();
    
    // ç§»é™¤å¼€å¤´å’Œç»“å°¾çš„è¿å­—ç¬¦
    slug.trim_matches('-').to_string()
}

/// éªŒè¯é‚®ç®±æ ¼å¼
pub fn is_valid_email(email: &str) -> bool {
    let email_re = Regex::new(r"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$").unwrap();
    email_re.is_match(email)
}

/// æ ¼å¼åŒ–ç›¸å¯¹æ—¶é—´
pub fn format_relative_time(datetime: DateTime<Utc>) -> String {
    let now = Utc::now();
    let duration = now - datetime;
    
    let seconds = duration.num_seconds();
    let minutes = duration.num_minutes();
    let hours = duration.num_hours();
    let days = duration.num_days();
    
    if seconds < 60 {
        "åˆšåˆš".to_string()
    } else if minutes < 60 {
        format!("{}åˆ†é’Ÿå‰", minutes)
    } else if hours < 24 {
        format!("{}å°æ—¶å‰", hours)
    } else if days < 7 {
        format!("{}å¤©å‰", days)
    } else if days < 30 {
        format!("{}å‘¨å‰", days / 7)
    } else if days < 365 {
        format!("{}ä¸ªæœˆå‰", days / 30)
    } else {
        format!("{}å¹´å‰", days / 365)
    }
}

/// éªŒè¯æ–‡ç« æ ‡é¢˜
pub fn validate_article_title(title: &str) -> Result<(), &'static str> {
    let title = title.trim();
    if title.is_empty() {
        return Err("æ ‡é¢˜ä¸èƒ½ä¸ºç©º");
    }
    if title.len() > 200 {
        return Err("æ ‡é¢˜ä¸èƒ½è¶…è¿‡200ä¸ªå­—ç¬¦");
    }
    Ok(())
}

/// éªŒè¯æ–‡ç« å†…å®¹
pub fn validate_article_content(content: &str) -> Result<(), &'static str> {
    let content = content.trim();
    if content.is_empty() {
        return Err("å†…å®¹ä¸èƒ½ä¸ºç©º");
    }
    if content.len() > 50000 {
        return Err("å†…å®¹ä¸èƒ½è¶…è¿‡50000ä¸ªå­—ç¬¦");
    }
    Ok(())
}

/// è®¡ç®—é˜…è¯»æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
pub fn calculate_read_time(content: &str) -> u32 {
    let word_count = content.split_whitespace().count();
    // å‡è®¾å¹³å‡é˜…è¯»é€Ÿåº¦æ˜¯æ¯åˆ†é’Ÿ200ä¸ªè¯
    let read_time = (word_count as f64 / 200.0).ceil() as u32;
    std::cmp::max(1, read_time)
}

/// ç”Ÿæˆéšæœºå­—ç¬¦ä¸²
pub fn generate_random_string(length: usize) -> String {
    use rand::{distributions::Alphanumeric, Rng};
    rand::thread_rng()
        .sample_iter(&Alphanumeric)
        .take(length)
        .map(char::from)
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_slugify() {
        assert_eq!(slugify("Hello World"), "hello-world");
        assert_eq!(slugify("Rust ç¼–ç¨‹è¯­è¨€"), "rust-");
        assert_eq!(slugify("  Multiple   Spaces  "), "multiple-spaces");
    }
    
    #[test]
    fn test_strip_markdown() {
        let markdown = "# Title\n\nThis is **bold** and *italic* text with `code`.";
        let stripped = strip_markdown(markdown);
        assert_eq!(stripped, "Title This is bold and italic text with code.");
    }
    
    #[test]
    fn test_generate_excerpt() {
        let content = "This is a long article content that should be truncated.";
        let excerpt = generate_excerpt(content, 20);
        assert_eq!(excerpt, "This is a long...");
    }
    
    #[test]
    fn test_is_valid_email() {
        assert!(is_valid_email("test@example.com"));
        assert!(!is_valid_email("invalid-email"));
        assert!(!is_valid_email("test@"));
    }
    
    #[test]
    fn test_calculate_read_time() {
        let content = "word ".repeat(400); // 400 words
        let read_time = calculate_read_time(&content);
        assert_eq!(read_time, 2); // 400 words / 200 words per minute = 2 minutes
    }
}
```
 ä»£ç 
```dockerfile
# ## Dockerfile
# ä½¿ç”¨å®˜æ–¹ Rust é•œåƒä½œä¸ºæ„å»ºç¯å¢ƒ
FROM rust:1.75 as builder

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ Cargo.toml å’Œ Cargo.lock
COPY Cargo.toml Cargo.lock ./

# åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„ main.rs æ¥ç¼“å­˜ä¾èµ–
RUN mkdir src && echo "fn main() {}" > src/main.rs

# æ„å»ºä¾èµ–ï¼ˆè¿™ä¸€å±‚ä¼šè¢«ç¼“å­˜ï¼‰
RUN cargo build --release
RUN rm src/main.rs

# å¤åˆ¶æºä»£ç 
COPY src ./src

# æ„å»ºåº”ç”¨
RUN cargo build --release

# ä½¿ç”¨è¾ƒå°çš„åŸºç¡€é•œåƒä½œä¸ºè¿è¡Œç¯å¢ƒ
FROM debian:bookworm-slim

# å®‰è£…è¿è¡Œæ—¶ä¾èµ–
RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    libpq5 \
    && rm -rf /var/lib/apt/lists/*

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# ä»æ„å»ºé•œåƒå¤åˆ¶å¯æ‰§è¡Œæ–‡ä»¶
COPY --from=builder /app/target/release/blog-api /app/blog-api

# æ›´æ”¹æ–‡ä»¶æ‰€æœ‰è€…
RUN chown -R appuser:appuser /app

# åˆ‡æ¢åˆ°åº”ç”¨ç”¨æˆ·
USER appuser

# æš´éœ²ç«¯å£
EXPOSE 3001

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV RUST_LOG=info
ENV PORT=3001

# è¿è¡Œåº”ç”¨
CMD ["./blog-api"]
```
 ä»£ç 
```yaml
# ## docker-compose.yml
version: '3.8'

services:
  # PostgreSQL æ•°æ®åº“
  postgres:
    image: postgres:15
    container_name: blog_postgres
    environment:
      POSTGRES_DB: blog_api
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres123
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis (å¯é€‰ï¼Œç”¨äºç¼“å­˜å’Œä¼šè¯å­˜å‚¨)
  redis:
    image: redis:7-alpine
    container_name: blog_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Blog API åº”ç”¨
  blog-api:
    build: .
    container_name: blog_api
    environment:
      # æ•°æ®åº“é…ç½®
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASSWORD: postgres123
      DB_NAME: blog_api
      
      # åº”ç”¨é…ç½®
      PORT: 3001
      RUST_LOG: info
      
      # Redis é…ç½® (å¯é€‰)
      REDIS_URL: redis://redis:6379
      
      # JWT å¯†é’¥ (ç”Ÿäº§ç¯å¢ƒåº”è¯¥ä½¿ç”¨æ›´å®‰å…¨çš„å¯†é’¥)
      JWT_SECRET: your-super-secret-jwt-key-change-in-production
    ports:
      - "3001:3001"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      # å¼€å‘æ—¶å¯ä»¥æŒ‚è½½æºç è¿›è¡Œçƒ­é‡è½½
      - ./src:/app/src:ro
    restart: unless-stopped

  # Nginx åå‘ä»£ç† (å¯é€‰)
  nginx:
    image: nginx:alpine
    container_name: blog_nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - blog-api
    restart: unless-stopped

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local

networks:
  default:
    name: blog_network
```
 ä»£ç 
```bash
# ## .env.example
# å¤åˆ¶æ­¤æ–‡ä»¶ä¸º .env å¹¶å¡«å…¥å®é™…çš„é…ç½®å€¼

# ======================
# åº”ç”¨é…ç½®
# ======================
PORT=3001
RUST_LOG=info

# ======================
# æ•°æ®åº“é…ç½®
# ======================
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=your_db_password_here
DB_NAME=blog_api

# ======================
# Redis é…ç½® (å¯é€‰)
# ======================
REDIS_URL=redis://localhost:6379

# ======================
# JWT é…ç½®
# ======================
JWT_SECRET=your-super-secret-jwt-key-change-this-in-production
JWT_EXPIRATION=86400  # 24 hours in seconds

# ======================
# Google OAuth é…ç½®
# ======================
GOOGLE_CLIENT_ID=your-google-oauth-client-id
GOOGLE_CLIENT_SECRET=your-google-oauth-client-secret

# ======================
# æ–‡ä»¶ä¸Šä¼ é…ç½®
# ======================
UPLOAD_DIR=./uploads
MAX_FILE_SIZE=10485760  # 10MB in bytes
ALLOWED_FILE_TYPES=jpg,jpeg,png,gif,webp

# ======================
# é‚®ä»¶é…ç½® (å¯é€‰)
# ======================
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password
FROM_EMAIL=noreply@yourdomain.com
FROM_NAME=Your Blog Name

# ======================
# å¤–éƒ¨æœåŠ¡é…ç½®
# ======================
# Cloudinary (å›¾ç‰‡å­˜å‚¨ï¼Œå¯é€‰)
CLOUDINARY_CLOUD_NAME=your-cloud-name
CLOUDINARY_API_KEY=your-api-key
CLOUDINARY_API_SECRET=your-api-secret

# Amazon S3 (æ–‡ä»¶å­˜å‚¨ï¼Œå¯é€‰)
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
AWS_REGION=us-east-1
S3_BUCKET_NAME=your-bucket-name

# ======================
# å®‰å…¨é…ç½®
# ======================
# CORS å…è®¸çš„åŸŸåï¼Œç”¨é€—å·åˆ†éš”
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,https://yourdomain.com

# Session å¯†é’¥
SESSION_SECRET=your-session-secret-key-change-this

# ======================
# ç¼“å­˜é…ç½®
# ======================
CACHE_TTL=3600  # 1 hour in seconds
ENABLE_CACHE=true

# ======================
# ç›‘æ§å’Œæ—¥å¿—é…ç½®
# ======================
# Sentry (é”™è¯¯ç›‘æ§ï¼Œå¯é€‰)
SENTRY_DSN=your-sentry-dsn-url

# æ—¥å¿—çº§åˆ« (trace, debug, info, warn, error)
LOG_LEVEL=info

# ======================
# åŠŸèƒ½å¼€å…³
# ======================
ENABLE_REGISTRATION=true
ENABLE_COMMENTS=true
ENABLE_VOTING=true
ENABLE_EMAIL_NOTIFICATIONS=false

# ======================
# é€Ÿç‡é™åˆ¶é…ç½®
# ======================
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST_SIZE=10

# ======================
# æœç´¢é…ç½®
# ======================
# Elasticsearch (å¯é€‰)
ELASTICSEARCH_URL=http://localhost:9200
ENABLE_FULL_TEXT_SEARCH=false
```
 ä»£ç 
```rust
// ## tests/integration_tests.rs
use axum::{
    body::Body,
    http::{Method, Request, StatusCode},
    Router,
};
use serde_json::{json, Value};
use tower::ServiceExt;

// æ³¨æ„ï¼šè¿™äº›æµ‹è¯•éœ€è¦è¿è¡Œä¸­çš„æ•°æ®åº“
// åœ¨å®é™…é¡¹ç›®ä¸­ï¼Œä½ å¯èƒ½æƒ³è¦ä½¿ç”¨æµ‹è¯•æ•°æ®åº“æˆ–è€… mock

#[tokio::test]
async fn test_health_check() {
    let app = create_test_app().await;

    let response = app
        .oneshot(
            Request::builder()
                .uri("/api/health")
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();

    assert_eq!(response.status(), StatusCode::OK);
}

#[tokio::test]
async fn test_get_articles() {
    let app = create_test_app().await;

    let response = app
        .oneshot(
            Request::builder()
                .uri("/api/articles")
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();

    assert_eq!(response.status(), StatusCode::OK);
}

#[tokio::test]
async fn test_get_categories() {
    let app = create_test_app().await;

    let response = app
        .oneshot(
            Request::builder()
                .uri("/api/categories")
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();

    assert_eq!(response.status(), StatusCode::OK);
}

#[tokio::test]
async fn test_create_article() {
    let app = create_test_app().await;

    let article_data = json!({
        "title": "Test Article",
        "content": "This is a test article content.",
        "excerpt": "Test excerpt",
        "status": "DRAFT"
    });

    let response = app
        .oneshot(
            Request::builder()
                .method(Method::POST)
                .uri("/api/articles")
                .header("content-type", "application/json")
                .body(Body::from(article_data.to_string()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert_eq!(response.status(), StatusCode::OK);
}

#[tokio::test]
async fn test_graphql_query() {
    let app = create_test_app().await;

    let query = json!({
        "query": "query { articles { articles { id title } } }"
    });

    let response = app
        .oneshot(
            Request::builder()
                .method(Method::POST)
                .uri("/graphql")
                .header("content-type", "application/json")
                .body(Body::from(query.to_string()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert_eq!(response.status(), StatusCode::OK);
}

#[tokio::test]
async fn test_invalid_article_creation() {
    let app = create_test_app().await;

    let invalid_data = json!({
        "title": "", // ç©ºæ ‡é¢˜åº”è¯¥å¤±è´¥
        "content": "Some content"
    });

    let response = app
        .oneshot(
            Request::builder()
                .method(Method::POST)
                .uri("/api/articles")
                .header("content-type", "application/json")
                .body(Body::from(invalid_data.to_string()))
                .unwrap(),
        )
        .await
        .unwrap();

    assert_eq!(response.status(), StatusCode::BAD_REQUEST);
}

#[tokio::test]
async fn test_cors_headers() {
    let app = create_test_app().await;

    let response = app
        .oneshot(
            Request::builder()
                .method(Method::OPTIONS)
                .uri("/api/articles")
                .header("origin", "http://localhost:3000")
                .header("access-control-request-method", "POST")
                .body(Body::empty())
                .unwrap(),
        )
        .await
        .unwrap();

    assert_eq!(response.status(), StatusCode::OK);
    
    // æ£€æŸ¥ CORS å¤´æ˜¯å¦å­˜åœ¨
    assert!(response.headers().contains_key("access-control-allow-origin"));
}

// è¾…åŠ©å‡½æ•°ï¼šåˆ›å»ºæµ‹è¯•åº”ç”¨
async fn create_test_app() -> Router {
    // è¿™é‡Œåº”è¯¥åˆ›å»ºä¸€ä¸ªæµ‹è¯•ç‰ˆæœ¬çš„åº”ç”¨
    // åœ¨å®é™…å®ç°ä¸­ï¼Œä½ éœ€è¦ï¼š
    // 1. ä½¿ç”¨æµ‹è¯•æ•°æ®åº“
    // 2. å¯èƒ½éœ€è¦ mock ä¸€äº›å¤–éƒ¨æœåŠ¡
    // 3. è®¾ç½®æµ‹è¯•ç‰¹å®šçš„é…ç½®
    
    todo!("éœ€è¦å®ç°æµ‹è¯•åº”ç”¨çš„åˆ›å»ºé€»è¾‘")
}

// è¾…åŠ©å‡½æ•°ï¼šæ¸…ç†æµ‹è¯•æ•°æ®
async fn cleanup_test_data() {
    // æ¸…ç†æµ‹è¯•è¿‡ç¨‹ä¸­åˆ›å»ºçš„æ•°æ®
    todo!("å®ç°æµ‹è¯•æ•°æ®æ¸…ç†")
}

// æµ‹è¯•æ•°æ®åº“è¿æ¥
#[tokio::test]
async fn test_database_connection() {
    // æµ‹è¯•æ•°æ®åº“è¿æ¥æ˜¯å¦æ­£å¸¸
    todo!("å®ç°æ•°æ®åº“è¿æ¥æµ‹è¯•")
}

// æµ‹è¯•ç”¨æˆ·è®¤è¯æµç¨‹
#[tokio::test]
async fn test_authentication_flow() {
    // æµ‹è¯•ç”¨æˆ·ç™»å½•ã€token éªŒè¯ç­‰
    todo!("å®ç°è®¤è¯æµç¨‹æµ‹è¯•")
}

// æµ‹è¯•æ–‡ç« çš„å®Œæ•´ CRUD æ“ä½œ
#[tokio::test]
async fn test_article_crud_operations() {
    // æµ‹è¯•åˆ›å»ºã€è¯»å–ã€æ›´æ–°ã€åˆ é™¤æ–‡ç« çš„å®Œæ•´æµç¨‹
    todo!("å®ç°æ–‡ç«  CRUD æµ‹è¯•")
}

// æ€§èƒ½æµ‹è¯•ï¼šå¤§é‡æ–‡ç« æŸ¥è¯¢
#[tokio::test]
async fn test_large_article_query_performance() {
    // æµ‹è¯•åœ¨å¤§é‡æ•°æ®ä¸‹çš„æŸ¥è¯¢æ€§èƒ½
    todo!("å®ç°æ€§èƒ½æµ‹è¯•")
}

// æµ‹è¯• GraphQL é”™è¯¯å¤„ç†
#[tokio::test]
async fn test_graphql_error_handling() {
    // æµ‹è¯• GraphQL æŸ¥è¯¢çš„é”™è¯¯å¤„ç†
    todo!("å®ç° GraphQL é”™è¯¯å¤„ç†æµ‹è¯•")
}
```
 ä»£ç 
```makefile
# ## Makefile
.PHONY: help dev build test clean docker-build docker-up docker-down setup migrate lint fmt check docs

# é»˜è®¤ç›®æ ‡
help: ## æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
	@echo "å¯ç”¨çš„å‘½ä»¤:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'

# å¼€å‘ç›¸å…³
dev: ## å¯åŠ¨å¼€å‘æœåŠ¡å™¨ (å¸¦çƒ­é‡è½½)
	cargo watch -x run

build: ## æ„å»ºé¡¹ç›®
	cargo build --release

build-debug: ## æ„å»ºè°ƒè¯•ç‰ˆæœ¬
	cargo build

run: ## è¿è¡Œé¡¹ç›®
	cargo run

# æµ‹è¯•ç›¸å…³
test: ## è¿è¡Œæ‰€æœ‰æµ‹è¯•
	cargo test

test-unit: ## è¿è¡Œå•å…ƒæµ‹è¯•
	cargo test --lib

test-integration: ## è¿è¡Œé›†æˆæµ‹è¯•
	cargo test --test integration_tests

test-coverage: ## ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
	cargo tarpaulin --out Html --output-dir coverage

# ä»£ç è´¨é‡
lint: ## è¿è¡Œ clippy æ£€æŸ¥ä»£ç è´¨é‡
	cargo clippy -- -D warnings

fmt: ## æ ¼å¼åŒ–ä»£ç 
	cargo fmt

fmt-check: ## æ£€æŸ¥ä»£ç æ ¼å¼
	cargo fmt -- --check

check: ## æ£€æŸ¥ä»£ç  (ç¼–è¯‘æ£€æŸ¥)
	cargo check

audit: ## å®‰å…¨å®¡è®¡
	cargo audit

# æ•°æ®åº“ç›¸å…³
setup-db: ## åˆ›å»ºæ•°æ®åº“
	createdb blog_api || true

drop-db: ## åˆ é™¤æ•°æ®åº“
	dropdb blog_api || true

reset-db: drop-db setup-db ## é‡ç½®æ•°æ®åº“

migrate: ## è¿è¡Œæ•°æ®åº“è¿ç§» (è‡ªåŠ¨æ‰§è¡Œ)
	cargo run

psql: ## è¿æ¥åˆ° PostgreSQL
	psql -d blog_api

# Docker ç›¸å…³
docker-build: ## æ„å»º Docker é•œåƒ
	docker build -t blog-api .

docker-up: ## å¯åŠ¨ Docker å®¹å™¨
	docker-compose up -d

docker-down: ## åœæ­¢ Docker å®¹å™¨
	docker-compose down

docker-logs: ## æŸ¥çœ‹ Docker æ—¥å¿—
	docker-compose logs -f blog-api

docker-clean: ## æ¸…ç† Docker èµ„æº
	docker-compose down -v
	docker system prune -f

# ç¯å¢ƒè®¾ç½®
setup: ## åˆå§‹åŒ–å¼€å‘ç¯å¢ƒ
	@echo "ğŸ”§ è®¾ç½®å¼€å‘ç¯å¢ƒ..."
	@if [ ! -f .env ]; then cp .env.example .env; echo "âœ… åˆ›å»º .env æ–‡ä»¶"; fi
	cargo install cargo-watch cargo-tarpaulin cargo-audit
	@echo "âœ… å¼€å‘ç¯å¢ƒè®¾ç½®å®Œæˆ"

install-deps: ## å®‰è£…å¼€å‘ä¾èµ–
	cargo install cargo-watch cargo-tarpaulin cargo-audit sqlx-cli

# éƒ¨ç½²ç›¸å…³
deploy-staging: ## éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ
	@echo "ğŸš€ éƒ¨ç½²åˆ°æµ‹è¯•ç¯å¢ƒ..."
	docker build -t blog-api:staging .
	# è¿™é‡Œæ·»åŠ ä½ çš„éƒ¨ç½²è„šæœ¬

deploy-prod: ## éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ
	@echo "ğŸš€ éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ..."
	docker build -t blog-api:prod .
	# è¿™é‡Œæ·»åŠ ä½ çš„ç”Ÿäº§éƒ¨ç½²è„šæœ¬

# æ–‡æ¡£ç›¸å…³
docs: ## ç”Ÿæˆæ–‡æ¡£
	cargo doc --open

docs-build: ## æ„å»ºæ–‡æ¡£
	cargo doc --no-deps

# æ•°æ®ç›¸å…³
seed-data: ## æ’å…¥ç¤ºä¾‹æ•°æ®
	@echo "ğŸŒ± æ’å…¥ç¤ºä¾‹æ•°æ®..."
	# è¿™é‡Œå¯ä»¥æ·»åŠ æ’å…¥ç¤ºä¾‹æ•°æ®çš„è„šæœ¬

backup-db: ## å¤‡ä»½æ•°æ®åº“
	@echo "ğŸ’¾ å¤‡ä»½æ•°æ®åº“..."
	pg_dump blog_api > backup_$(shell date +%Y%m%d_%H%M%S).sql

restore-db: ## æ¢å¤æ•°æ®åº“ (éœ€è¦æŒ‡å®š BACKUP_FILE)
	@if [ -z "$(BACKUP_FILE)" ]; then echo "è¯·æŒ‡å®š BACKUP_FILE: make restore-db BACKUP_FILE=backup.sql"; exit 1; fi
	psql -d blog_api < $(BACKUP_FILE)

# æ¸…ç†
clean: ## æ¸…ç†æ„å»ºäº§ç‰©
	cargo clean
	rm -rf target/
	rm -rf coverage/

clean-all: clean docker-clean ## æ¸…ç†æ‰€æœ‰å†…å®¹

# å®‰å…¨æ£€æŸ¥
security-check: audit ## è¿è¡Œå®‰å…¨æ£€æŸ¥
	@echo "ğŸ”’ è¿è¡Œå®‰å…¨æ£€æŸ¥..."

# æ€§èƒ½æµ‹è¯•
bench: ## è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
	cargo bench

# å¼€å‘å·¥å…·
watch-test: ## ç›‘å¬æ–‡ä»¶å˜åŒ–å¹¶è¿è¡Œæµ‹è¯•
	cargo watch -x test

watch-check: ## ç›‘å¬æ–‡ä»¶å˜åŒ–å¹¶æ£€æŸ¥ä»£ç 
	cargo watch -x check

watch-clippy: ## ç›‘å¬æ–‡ä»¶å˜åŒ–å¹¶è¿è¡Œ clippy
	cargo watch -x "clippy -- -D warnings"

# GraphQL ç›¸å…³
graphql-schema: ## å¯¼å‡º GraphQL Schema
	@echo "ğŸ“‹ å¯¼å‡º GraphQL Schema..."
	curl -X POST \
		-H "Content-Type: application/json" \
		-d '{"query": "query IntrospectionQuery { __schema { queryType { name } mutationType { name } subscriptionType { name } types { ...FullType } directives { name description locations args { ...InputValue } } } } fragment FullType on __Type { kind name description fields(includeDeprecated: true) { name description args { ...InputValue } type { ...TypeRef } isDeprecated deprecationReason } inputFields { ...InputValue } interfaces { ...TypeRef } enumValues(includeDeprecated: true) { name description isDeprecated deprecationReason } possibleTypes { ...TypeRef } } fragment InputValue on __InputValue { name description type { ...TypeRef } defaultValue } fragment TypeRef on __Type { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name ofType { kind name } } } } } } } }"}' \
		http://localhost:3001/graphql > schema.json

# ç‰ˆæœ¬ç®¡ç†
tag: ## åˆ›å»ºç‰ˆæœ¬æ ‡ç­¾ (éœ€è¦æŒ‡å®š VERSION)
	@if [ -z "$(VERSION)" ]; then echo "è¯·æŒ‡å®šç‰ˆæœ¬: make tag VERSION=v1.0.0"; exit 1; fi
	git tag -a $(VERSION) -m "Release $(VERSION)"
	git push origin $(VERSION)

release: test lint fmt-check ## å‡†å¤‡å‘å¸ƒ (è¿è¡Œæ‰€æœ‰æ£€æŸ¥)
	@echo "âœ… å‘å¸ƒå‰æ£€æŸ¥é€šè¿‡"

# ç›‘æ§å’Œæ—¥å¿—
logs: ## æŸ¥çœ‹åº”ç”¨æ—¥å¿—
	tail -f logs/app.log

monitor: ## å¯åŠ¨ç›‘æ§ (å¦‚æœé…ç½®äº†çš„è¯)
	@echo "ğŸ“Š å¯åŠ¨ç›‘æ§..."

# ç»Ÿè®¡
stats: ## æ˜¾ç¤ºé¡¹ç›®ç»Ÿè®¡ä¿¡æ¯
	@echo "ğŸ“Š é¡¹ç›®ç»Ÿè®¡:"
	@echo "ä»£ç è¡Œæ•°:"
	@find src -name "*.rs" | xargs wc -l | tail -1
	@echo "æ–‡ä»¶æ•°é‡:"
	@find src -name "*.rs" | wc -l
	@echo "ä¾èµ–æ•°é‡:"
	@grep -c "^[^#].*=" Cargo.toml || true

# å…¨å¥—æ£€æŸ¥
full-check: clean build test lint fmt-check audit ## è¿è¡Œå®Œæ•´çš„ä»£ç æ£€æŸ¥æµç¨‹
	@echo "âœ… æ‰€æœ‰æ£€æŸ¥å®Œæˆ"

# å¼€å‘æœåŠ¡å™¨ (åŒ…å«æ•°æ®åº“)
dev-full: docker-up dev ## å¯åŠ¨å®Œæ•´å¼€å‘ç¯å¢ƒ (æ•°æ®åº“ + åº”ç”¨)
```

